{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81987ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb297043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 21:46:10.062470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: /usr/lib/x86_64-linux-gnu/libcuda.so.1: file too short; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-07-11 21:46:10.062491: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-11 21:46:10.062506: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-07-11 21:46:10.062650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import sklearn\n",
    "import tensorflow as tf\n",
    "import es_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f41ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''labels = ['label:LYING_DOWN',\n",
    " 'label:SITTING',\n",
    " 'label:FIX_walking',\n",
    " 'label:FIX_running',\n",
    " 'label:BICYCLING',\n",
    " 'label:SLEEPING',\n",
    " 'label:LAB_WORK',\n",
    " 'label:IN_CLASS',\n",
    " 'label:IN_A_MEETING',\n",
    " 'label:LOC_main_workplace',\n",
    " 'label:OR_indoors',\n",
    " 'label:OR_outside',\n",
    " 'label:IN_A_CAR',\n",
    " 'label:ON_A_BUS',\n",
    " 'label:DRIVE_-_I_M_THE_DRIVER',\n",
    " 'label:DRIVE_-_I_M_A_PASSENGER',\n",
    " 'label:LOC_home',\n",
    " 'label:FIX_restaurant',\n",
    " 'label:PHONE_IN_POCKET',\n",
    " 'label:OR_exercise',\n",
    " 'label:COOKING',\n",
    " 'label:SHOPPING',\n",
    " 'label:STROLLING',\n",
    " 'label:DRINKING__ALCOHOL_',\n",
    " 'label:BATHING_-_SHOWER',\n",
    " 'label:CLEANING',\n",
    " 'label:DOING_LAUNDRY',\n",
    " 'label:WASHING_DISHES',\n",
    " 'label:WATCHING_TV',\n",
    " 'label:SURFING_THE_INTERNET',\n",
    " 'label:AT_A_PARTY',\n",
    " 'label:AT_A_BAR',\n",
    " 'label:LOC_beach',\n",
    " 'label:SINGING',\n",
    " 'label:TALKING',\n",
    " 'label:COMPUTER_WORK',\n",
    " 'label:EATING',\n",
    " 'label:TOILET',\n",
    " 'label:GROOMING',\n",
    " 'label:DRESSING',\n",
    " 'label:AT_THE_GYM',\n",
    " 'label:STAIRS_-_GOING_UP',\n",
    " 'label:STAIRS_-_GOING_DOWN',\n",
    " 'label:ELEVATOR',\n",
    " 'label:OR_standing',\n",
    " 'label:AT_SCHOOL',\n",
    " 'label:PHONE_IN_HAND',\n",
    " 'label:PHONE_IN_BAG',\n",
    " 'label:PHONE_ON_TABLE',\n",
    " 'label:WITH_CO-WORKERS',\n",
    " 'label:WITH_FRIENDS']\n",
    "\n",
    "len(labels)'''\n",
    "\n",
    "labels = [\n",
    "    'label:OR_standing',\n",
    "    'label:SITTING',\n",
    "    'label:LYING_DOWN',\n",
    "    'label:FIX_running',\n",
    "    'label:FIX_walking',\n",
    "    'label:BICYCLING'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf5a5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a2e346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train-test shape: (3168, 226) - X test shape: (792, 226)\n",
      "y train-test shape: (3168, 6) - y test shape: (792, 6)\n",
      "Epoch 1/40\n",
      "254/254 [==============================] - 1s 1ms/step - loss: 1.0344 - val_loss: 1.0746\n",
      "Epoch 2/40\n",
      "254/254 [==============================] - 0s 774us/step - loss: 1.0081 - val_loss: 1.0420\n",
      "Epoch 3/40\n",
      "254/254 [==============================] - 0s 850us/step - loss: 0.9953 - val_loss: 1.0638\n",
      "Epoch 4/40\n",
      "254/254 [==============================] - 0s 823us/step - loss: 0.9971 - val_loss: 1.0435\n",
      "Epoch 5/40\n",
      "254/254 [==============================] - 0s 808us/step - loss: 1.0007 - val_loss: 1.0394\n",
      "Epoch 6/40\n",
      "254/254 [==============================] - 0s 865us/step - loss: 1.0015 - val_loss: 1.0412\n",
      "Epoch 7/40\n",
      "254/254 [==============================] - 0s 853us/step - loss: 0.9955 - val_loss: 1.0417\n",
      "Epoch 8/40\n",
      "254/254 [==============================] - 0s 822us/step - loss: 1.0002 - val_loss: 1.0443\n",
      "Epoch 9/40\n",
      "254/254 [==============================] - 0s 763us/step - loss: 0.9976 - val_loss: 1.0404\n",
      "Epoch 10/40\n",
      "254/254 [==============================] - 0s 823us/step - loss: 0.9997 - val_loss: 1.0644\n",
      "Epoch 11/40\n",
      "254/254 [==============================] - 0s 871us/step - loss: 0.9999 - val_loss: 1.0772\n",
      "Epoch 12/40\n",
      "254/254 [==============================] - 0s 809us/step - loss: 0.9969 - val_loss: 1.0346\n",
      "Epoch 13/40\n",
      "254/254 [==============================] - 0s 803us/step - loss: 0.9979 - val_loss: 1.0494\n",
      "Epoch 14/40\n",
      "254/254 [==============================] - 0s 816us/step - loss: 1.0023 - val_loss: 1.0379\n",
      "Epoch 15/40\n",
      "254/254 [==============================] - 0s 815us/step - loss: 0.9938 - val_loss: 1.0337\n",
      "Epoch 16/40\n",
      "254/254 [==============================] - 0s 860us/step - loss: 0.9941 - val_loss: 1.0411\n",
      "Epoch 17/40\n",
      "254/254 [==============================] - 0s 777us/step - loss: 1.0007 - val_loss: 1.0334\n",
      "Epoch 18/40\n",
      "254/254 [==============================] - 0s 813us/step - loss: 1.0007 - val_loss: 1.0376\n",
      "Epoch 19/40\n",
      "254/254 [==============================] - 0s 802us/step - loss: 0.9953 - val_loss: 1.0335\n",
      "Epoch 20/40\n",
      "254/254 [==============================] - 0s 845us/step - loss: 0.9967 - val_loss: 1.0489\n",
      "Epoch 21/40\n",
      "254/254 [==============================] - 0s 806us/step - loss: 0.9998 - val_loss: 1.0464\n",
      "Epoch 22/40\n",
      "254/254 [==============================] - 0s 849us/step - loss: 0.9968 - val_loss: 1.0482\n",
      "Epoch 23/40\n",
      "254/254 [==============================] - 0s 909us/step - loss: 1.0001 - val_loss: 1.0356\n",
      "Epoch 24/40\n",
      "254/254 [==============================] - 0s 886us/step - loss: 0.9962 - val_loss: 1.0503\n",
      "Epoch 25/40\n",
      "254/254 [==============================] - 0s 837us/step - loss: 0.9954 - val_loss: 1.0425\n",
      "Epoch 26/40\n",
      "254/254 [==============================] - 0s 795us/step - loss: 1.0003 - val_loss: 1.0427\n",
      "Epoch 27/40\n",
      "254/254 [==============================] - 0s 878us/step - loss: 0.9987 - val_loss: 1.1071\n",
      "Epoch 28/40\n",
      "254/254 [==============================] - 0s 823us/step - loss: 1.0001 - val_loss: 1.0351\n",
      "Epoch 29/40\n",
      "254/254 [==============================] - 0s 850us/step - loss: 0.9977 - val_loss: 1.0439\n",
      "Epoch 30/40\n",
      "254/254 [==============================] - 0s 830us/step - loss: 0.9959 - val_loss: 1.0771\n",
      "Epoch 31/40\n",
      "254/254 [==============================] - 0s 851us/step - loss: 0.9959 - val_loss: 1.0489\n",
      "Epoch 32/40\n",
      "254/254 [==============================] - 0s 814us/step - loss: 1.0001 - val_loss: 1.0597\n",
      "Epoch 33/40\n",
      "254/254 [==============================] - 0s 808us/step - loss: 0.9973 - val_loss: 1.0484\n",
      "Epoch 34/40\n",
      "254/254 [==============================] - 0s 814us/step - loss: 1.0016 - val_loss: 1.0704\n",
      "Epoch 35/40\n",
      "254/254 [==============================] - 0s 802us/step - loss: 1.0020 - val_loss: 1.0379\n",
      "Epoch 36/40\n",
      "254/254 [==============================] - 0s 832us/step - loss: 0.9981 - val_loss: 1.0357\n",
      "Epoch 37/40\n",
      "254/254 [==============================] - 0s 825us/step - loss: 0.9948 - val_loss: 1.0384\n",
      "Epoch 38/40\n",
      "254/254 [==============================] - 0s 789us/step - loss: 0.9979 - val_loss: 1.0484\n",
      "Epoch 39/40\n",
      "254/254 [==============================] - 0s 837us/step - loss: 0.9970 - val_loss: 1.0440\n",
      "Epoch 40/40\n",
      "254/254 [==============================] - 0s 919us/step - loss: 0.9958 - val_loss: 1.0439\n",
      "25/25 [==============================] - 0s 474us/step - loss: 1.0490\n",
      "25/25 [==============================] - 0s 443us/step\n",
      "Test results - Loss - Accuracy: 1.0489941835403442\n",
      "Averaged Balanced Accuracy: 0.736929\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "Epoch 1/40\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 1.2069 - val_loss: 1.1770\n",
      "Epoch 2/40\n",
      "199/199 [==============================] - 0s 851us/step - loss: 3.0538 - val_loss: 5.1144\n",
      "Epoch 3/40\n",
      "199/199 [==============================] - 0s 847us/step - loss: 5.2792 - val_loss: 14.1008\n",
      "Epoch 4/40\n",
      "199/199 [==============================] - 0s 858us/step - loss: 10.1015 - val_loss: 20.3190\n",
      "Epoch 5/40\n",
      "199/199 [==============================] - 0s 797us/step - loss: 13.3548 - val_loss: 13.4959\n",
      "Epoch 6/40\n",
      "199/199 [==============================] - 0s 837us/step - loss: 17.0559 - val_loss: 7.8061\n",
      "Epoch 7/40\n",
      "199/199 [==============================] - 0s 930us/step - loss: 16.6508 - val_loss: 35.1397\n",
      "Epoch 8/40\n",
      "199/199 [==============================] - 0s 857us/step - loss: 21.4660 - val_loss: 10.3951\n",
      "Epoch 9/40\n",
      "199/199 [==============================] - 0s 805us/step - loss: 19.1084 - val_loss: 12.2391\n",
      "Epoch 10/40\n",
      "199/199 [==============================] - 0s 784us/step - loss: 24.3077 - val_loss: 41.4948\n",
      "Epoch 11/40\n",
      "199/199 [==============================] - 0s 830us/step - loss: 36.4319 - val_loss: 43.1389\n",
      "Epoch 12/40\n",
      "199/199 [==============================] - 0s 873us/step - loss: 27.9640 - val_loss: 23.6268\n",
      "Epoch 13/40\n",
      "199/199 [==============================] - 0s 853us/step - loss: 29.3136 - val_loss: 36.1772\n",
      "Epoch 14/40\n",
      "199/199 [==============================] - 0s 787us/step - loss: 35.6015 - val_loss: 25.5655\n",
      "Epoch 15/40\n",
      "199/199 [==============================] - 0s 863us/step - loss: 38.3589 - val_loss: 34.0720\n",
      "Epoch 16/40\n",
      "199/199 [==============================] - 0s 884us/step - loss: 39.3641 - val_loss: 26.4325\n",
      "Epoch 17/40\n",
      "199/199 [==============================] - 0s 843us/step - loss: 38.1989 - val_loss: 49.8809\n",
      "Epoch 18/40\n",
      "199/199 [==============================] - 0s 896us/step - loss: 42.4075 - val_loss: 92.0636\n",
      "Epoch 19/40\n",
      "199/199 [==============================] - 0s 826us/step - loss: 42.4764 - val_loss: 49.3783\n",
      "Epoch 20/40\n",
      "199/199 [==============================] - 0s 824us/step - loss: 47.1110 - val_loss: 57.3491\n",
      "Epoch 21/40\n",
      "199/199 [==============================] - 0s 780us/step - loss: 46.1422 - val_loss: 59.4006\n",
      "Epoch 22/40\n",
      "199/199 [==============================] - 0s 794us/step - loss: 52.1256 - val_loss: 13.6452\n",
      "Epoch 23/40\n",
      "199/199 [==============================] - 0s 884us/step - loss: 41.2998 - val_loss: 25.5074\n",
      "Epoch 24/40\n",
      "199/199 [==============================] - 0s 811us/step - loss: 42.8765 - val_loss: 20.9149\n",
      "Epoch 25/40\n",
      "199/199 [==============================] - 0s 842us/step - loss: 42.1353 - val_loss: 40.3293\n",
      "Epoch 26/40\n",
      "199/199 [==============================] - 0s 839us/step - loss: 48.3220 - val_loss: 60.9531\n",
      "Epoch 27/40\n",
      "199/199 [==============================] - 0s 862us/step - loss: 45.4702 - val_loss: 29.8482\n",
      "Epoch 28/40\n",
      "199/199 [==============================] - 0s 828us/step - loss: 56.1249 - val_loss: 54.1788\n",
      "Epoch 29/40\n",
      "199/199 [==============================] - 0s 919us/step - loss: 62.7090 - val_loss: 68.3083\n",
      "Epoch 30/40\n",
      "199/199 [==============================] - 0s 866us/step - loss: 53.7355 - val_loss: 25.0223\n",
      "Epoch 31/40\n",
      "199/199 [==============================] - 0s 834us/step - loss: 55.7505 - val_loss: 51.1761\n",
      "Epoch 32/40\n",
      "199/199 [==============================] - 0s 841us/step - loss: 56.3616 - val_loss: 79.2881\n",
      "Epoch 33/40\n",
      "199/199 [==============================] - 0s 812us/step - loss: 61.3702 - val_loss: 29.4808\n",
      "Epoch 34/40\n",
      "199/199 [==============================] - 0s 859us/step - loss: 58.5901 - val_loss: 59.5327\n",
      "Epoch 35/40\n",
      "199/199 [==============================] - 0s 933us/step - loss: 65.7554 - val_loss: 119.9502\n",
      "Epoch 36/40\n",
      "199/199 [==============================] - 0s 914us/step - loss: 80.9086 - val_loss: 90.6753\n",
      "Epoch 37/40\n",
      "199/199 [==============================] - 0s 821us/step - loss: 70.4084 - val_loss: 59.8778\n",
      "Epoch 38/40\n",
      "199/199 [==============================] - 0s 802us/step - loss: 62.3274 - val_loss: 42.4679\n",
      "Epoch 39/40\n",
      "199/199 [==============================] - 0s 891us/step - loss: 75.4427 - val_loss: 47.6419\n",
      "Epoch 40/40\n",
      "199/199 [==============================] - 0s 851us/step - loss: 60.6910 - val_loss: 82.4615\n",
      "20/20 [==============================] - 0s 491us/step - loss: 88.8611\n",
      "20/20 [==============================] - 0s 444us/step\n",
      "Test results - Loss - Accuracy: 88.86112976074219\n",
      "Averaged Balanced Accuracy: 0.614553\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "Epoch 1/40\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6117.6841 - val_loss: 35354.7383\n",
      "Epoch 2/40\n",
      "199/199 [==============================] - 0s 888us/step - loss: 64916.0742 - val_loss: 94890.0781\n",
      "Epoch 3/40\n",
      "199/199 [==============================] - 0s 919us/step - loss: 190967.2188 - val_loss: 183732.6094\n",
      "Epoch 4/40\n",
      "199/199 [==============================] - 0s 867us/step - loss: 406522.0312 - val_loss: 619148.5000\n",
      "Epoch 5/40\n",
      "199/199 [==============================] - 0s 880us/step - loss: 639388.5000 - val_loss: 394588.4062\n",
      "Epoch 6/40\n",
      "199/199 [==============================] - 0s 933us/step - loss: 914918.3125 - val_loss: 1432673.5000\n",
      "Epoch 7/40\n",
      "199/199 [==============================] - 0s 856us/step - loss: 1557934.3750 - val_loss: 2185836.7500\n",
      "Epoch 8/40\n",
      "199/199 [==============================] - 0s 852us/step - loss: 1295393.7500 - val_loss: 1713648.3750\n",
      "Epoch 9/40\n",
      "199/199 [==============================] - 0s 810us/step - loss: 2065342.5000 - val_loss: 768513.5625\n",
      "Epoch 10/40\n",
      "199/199 [==============================] - 0s 839us/step - loss: 2365742.2500 - val_loss: 3188390.5000\n",
      "Epoch 11/40\n",
      "199/199 [==============================] - 0s 854us/step - loss: 2891378.5000 - val_loss: 3973068.5000\n",
      "Epoch 12/40\n",
      "199/199 [==============================] - 0s 833us/step - loss: 3527241.2500 - val_loss: 6385284.5000\n",
      "Epoch 13/40\n",
      "199/199 [==============================] - 0s 832us/step - loss: 3314950.7500 - val_loss: 4287951.5000\n",
      "Epoch 14/40\n",
      "199/199 [==============================] - 0s 810us/step - loss: 3773444.0000 - val_loss: 2508112.2500\n",
      "Epoch 15/40\n",
      "199/199 [==============================] - 0s 839us/step - loss: 3746916.2500 - val_loss: 1201586.8750\n",
      "Epoch 16/40\n",
      "199/199 [==============================] - 0s 877us/step - loss: 4606253.0000 - val_loss: 3898279.5000\n",
      "Epoch 17/40\n",
      "199/199 [==============================] - 0s 878us/step - loss: 5386776.0000 - val_loss: 3080732.7500\n",
      "Epoch 18/40\n",
      "199/199 [==============================] - 0s 904us/step - loss: 6248296.0000 - val_loss: 7811775.0000\n",
      "Epoch 19/40\n",
      "199/199 [==============================] - 0s 854us/step - loss: 5849344.0000 - val_loss: 4829718.5000\n",
      "Epoch 20/40\n",
      "199/199 [==============================] - 0s 947us/step - loss: 6719239.5000 - val_loss: 2023711.8750\n",
      "Epoch 21/40\n",
      "199/199 [==============================] - 0s 890us/step - loss: 6871624.0000 - val_loss: 3168844.0000\n",
      "Epoch 22/40\n",
      "199/199 [==============================] - 0s 856us/step - loss: 8306655.0000 - val_loss: 6428857.0000\n",
      "Epoch 23/40\n",
      "199/199 [==============================] - 0s 897us/step - loss: 7068323.0000 - val_loss: 16512358.0000\n",
      "Epoch 24/40\n",
      "199/199 [==============================] - 0s 833us/step - loss: 8899600.0000 - val_loss: 14176079.0000\n",
      "Epoch 25/40\n",
      "199/199 [==============================] - 0s 824us/step - loss: 8603570.0000 - val_loss: 6224114.5000\n",
      "Epoch 26/40\n",
      "199/199 [==============================] - 0s 824us/step - loss: 10158024.0000 - val_loss: 16884110.0000\n",
      "Epoch 27/40\n",
      "199/199 [==============================] - 0s 881us/step - loss: 10119750.0000 - val_loss: 5740363.0000\n",
      "Epoch 28/40\n",
      "199/199 [==============================] - 0s 889us/step - loss: 11559359.0000 - val_loss: 14974022.0000\n",
      "Epoch 29/40\n",
      "199/199 [==============================] - 0s 864us/step - loss: 11251020.0000 - val_loss: 6912798.0000\n",
      "Epoch 30/40\n",
      "199/199 [==============================] - 0s 860us/step - loss: 12332728.0000 - val_loss: 7542529.0000\n",
      "Epoch 31/40\n",
      "199/199 [==============================] - 0s 838us/step - loss: 11947560.0000 - val_loss: 20150354.0000\n",
      "Epoch 32/40\n",
      "199/199 [==============================] - 0s 832us/step - loss: 13741804.0000 - val_loss: 13723475.0000\n",
      "Epoch 33/40\n",
      "199/199 [==============================] - 0s 893us/step - loss: 10958702.0000 - val_loss: 2886816.5000\n",
      "Epoch 34/40\n",
      "199/199 [==============================] - 0s 848us/step - loss: 14063058.0000 - val_loss: 10837555.0000\n",
      "Epoch 35/40\n",
      "199/199 [==============================] - 0s 818us/step - loss: 13536565.0000 - val_loss: 12123782.0000\n",
      "Epoch 36/40\n",
      "199/199 [==============================] - 0s 843us/step - loss: 18522462.0000 - val_loss: 23054838.0000\n",
      "Epoch 37/40\n",
      "199/199 [==============================] - 0s 878us/step - loss: 15714580.0000 - val_loss: 9941337.0000\n",
      "Epoch 38/40\n",
      "199/199 [==============================] - 0s 845us/step - loss: 15555928.0000 - val_loss: 1939793.2500\n",
      "Epoch 39/40\n",
      "199/199 [==============================] - 0s 848us/step - loss: 14381320.0000 - val_loss: 10842194.0000\n",
      "Epoch 40/40\n",
      "199/199 [==============================] - 0s 813us/step - loss: 17828900.0000 - val_loss: 17305666.0000\n",
      "20/20 [==============================] - 0s 609us/step - loss: 17000968.0000\n",
      "20/20 [==============================] - 0s 447us/step\n",
      "Test results - Loss - Accuracy: 17000968.0\n",
      "Averaged Balanced Accuracy: 0.582281\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "Epoch 1/40\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 1232.3500 - val_loss: 3606.6812\n",
      "Epoch 2/40\n",
      "199/199 [==============================] - 0s 853us/step - loss: 15426.9854 - val_loss: 36954.0898\n",
      "Epoch 3/40\n",
      "199/199 [==============================] - 0s 788us/step - loss: 39470.2617 - val_loss: 71517.0312\n",
      "Epoch 4/40\n",
      "199/199 [==============================] - 0s 843us/step - loss: 99728.3359 - val_loss: 45289.5430\n",
      "Epoch 5/40\n",
      "199/199 [==============================] - 0s 919us/step - loss: 129150.0859 - val_loss: 140401.3750\n",
      "Epoch 6/40\n",
      "199/199 [==============================] - 0s 827us/step - loss: 231332.7969 - val_loss: 422135.1875\n",
      "Epoch 7/40\n",
      "199/199 [==============================] - 0s 857us/step - loss: 296056.9688 - val_loss: 574831.1875\n",
      "Epoch 8/40\n",
      "199/199 [==============================] - 0s 832us/step - loss: 367267.0000 - val_loss: 228288.1250\n",
      "Epoch 9/40\n",
      "199/199 [==============================] - 0s 916us/step - loss: 552941.0000 - val_loss: 769524.1250\n",
      "Epoch 10/40\n",
      "199/199 [==============================] - 0s 884us/step - loss: 562049.3750 - val_loss: 773262.1250\n",
      "Epoch 11/40\n",
      "199/199 [==============================] - 0s 853us/step - loss: 647902.8125 - val_loss: 431678.9688\n",
      "Epoch 12/40\n",
      "199/199 [==============================] - 0s 852us/step - loss: 707092.9375 - val_loss: 934621.3125\n",
      "Epoch 13/40\n",
      "199/199 [==============================] - 0s 854us/step - loss: 876409.9375 - val_loss: 797099.6875\n",
      "Epoch 14/40\n",
      "199/199 [==============================] - 0s 908us/step - loss: 748726.0625 - val_loss: 447157.4688\n",
      "Epoch 15/40\n",
      "199/199 [==============================] - 0s 862us/step - loss: 896903.7500 - val_loss: 1209723.1250\n",
      "Epoch 16/40\n",
      "199/199 [==============================] - 0s 842us/step - loss: 1032737.1875 - val_loss: 1033804.6250\n",
      "Epoch 17/40\n",
      "199/199 [==============================] - 0s 880us/step - loss: 1199957.2500 - val_loss: 1326140.6250\n",
      "Epoch 18/40\n",
      "199/199 [==============================] - 0s 939us/step - loss: 1169781.8750 - val_loss: 977381.8125\n",
      "Epoch 19/40\n",
      "199/199 [==============================] - 0s 929us/step - loss: 1466143.0000 - val_loss: 1192182.2500\n",
      "Epoch 20/40\n",
      "199/199 [==============================] - 0s 793us/step - loss: 1309129.6250 - val_loss: 1565953.0000\n",
      "Epoch 21/40\n",
      "199/199 [==============================] - 0s 900us/step - loss: 1598277.7500 - val_loss: 794383.4375\n",
      "Epoch 22/40\n",
      "199/199 [==============================] - 0s 831us/step - loss: 1952641.2500 - val_loss: 1242440.0000\n",
      "Epoch 23/40\n",
      "199/199 [==============================] - 0s 865us/step - loss: 1778181.1250 - val_loss: 1526289.5000\n",
      "Epoch 24/40\n",
      "199/199 [==============================] - 0s 829us/step - loss: 1969386.3750 - val_loss: 1823457.1250\n",
      "Epoch 25/40\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 1616338.8750 - val_loss: 964298.5625\n",
      "Epoch 26/40\n",
      "199/199 [==============================] - 0s 847us/step - loss: 1863332.8750 - val_loss: 2636482.2500\n",
      "Epoch 27/40\n",
      "199/199 [==============================] - 0s 859us/step - loss: 2508406.0000 - val_loss: 1400476.2500\n",
      "Epoch 28/40\n",
      "199/199 [==============================] - 0s 910us/step - loss: 2410009.5000 - val_loss: 2084092.8750\n",
      "Epoch 29/40\n",
      "199/199 [==============================] - 0s 862us/step - loss: 2643488.0000 - val_loss: 2614691.5000\n",
      "Epoch 30/40\n",
      "199/199 [==============================] - 0s 872us/step - loss: 2762638.2500 - val_loss: 2966003.7500\n",
      "Epoch 31/40\n",
      "199/199 [==============================] - 0s 824us/step - loss: 2540853.0000 - val_loss: 2608942.2500\n",
      "Epoch 32/40\n",
      "199/199 [==============================] - 0s 853us/step - loss: 2771372.0000 - val_loss: 1817090.0000\n",
      "Epoch 33/40\n",
      "199/199 [==============================] - 0s 825us/step - loss: 3267310.0000 - val_loss: 1907286.3750\n",
      "Epoch 34/40\n",
      "199/199 [==============================] - 0s 827us/step - loss: 3293230.2500 - val_loss: 1587165.0000\n",
      "Epoch 35/40\n",
      "199/199 [==============================] - 0s 869us/step - loss: 3807676.5000 - val_loss: 6125025.0000\n",
      "Epoch 36/40\n",
      "199/199 [==============================] - 0s 798us/step - loss: 3279937.5000 - val_loss: 1723873.1250\n",
      "Epoch 37/40\n",
      "199/199 [==============================] - 0s 840us/step - loss: 3288051.7500 - val_loss: 3115559.0000\n",
      "Epoch 38/40\n",
      "199/199 [==============================] - 0s 834us/step - loss: 3758098.5000 - val_loss: 4573949.0000\n",
      "Epoch 39/40\n",
      "199/199 [==============================] - 0s 811us/step - loss: 4222921.5000 - val_loss: 3105208.0000\n",
      "Epoch 40/40\n",
      "199/199 [==============================] - 0s 846us/step - loss: 4215513.5000 - val_loss: 4256710.5000\n",
      "20/20 [==============================] - 0s 499us/step - loss: 4308504.5000\n",
      "20/20 [==============================] - 0s 455us/step\n",
      "Test results - Loss - Accuracy: 4308504.5\n",
      "Averaged Balanced Accuracy: 0.552017\n",
      "[0.7369293, 0.61455345, 0.58228123, 0.552017]\n",
      "0.7369293\n"
     ]
    }
   ],
   "source": [
    "paths = ['/home/nonroot/sample_data/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv', \n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv',\n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv',\n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv']\n",
    "bas = []\n",
    "\n",
    "for path in paths:\n",
    "\n",
    "    config = {\n",
    "            'df_path': path,\n",
    "            #'df_path': '../full_data/exp_/fold_0/raw_40.csv',\n",
    "            'neurons_1' : 32, \n",
    "            'neurons_2' : 16, \n",
    "            'labels': labels\n",
    "    }\n",
    "\n",
    "    har = utils.HAR(config)\n",
    "    test_results, ba = har.run()\n",
    "    #model, best_hps, best_epoch, test_results, ba = har.hypertunning()\n",
    "    bas.append(ba.numpy())\n",
    "    \n",
    "\n",
    "print(bas)\n",
    "print(max(bas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53eee92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573d13fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def nan_mse(y_actual, y_predicted):\\n    stack = tf.stack((tf.math.is_nan(y_actual), \\n                      tf.math.is_nan(y_predicted)),\\n                     axis=1)\\n    is_nans = tf.keras.backend.any(stack, axis=1)\\n    per_instance = tf.where(is_nans,\\n                            tf.zeros_like(y_actual),\\n                            tf.square(tf.subtract(y_predicted, y_actual)))\\n    print(stack)\\n    print(per_instance)\\n    return tf.reduce_mean(per_instance, axis=0)\\n\\nprint(nan_mse([1.,1.,np.nan,1.,0.], [1.,1.,0.,0.,np.nan]))'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def nan_mse(y_actual, y_predicted):\n",
    "    stack = tf.stack((tf.math.is_nan(y_actual), \n",
    "                      tf.math.is_nan(y_predicted)),\n",
    "                     axis=1)\n",
    "    is_nans = tf.keras.backend.any(stack, axis=1)\n",
    "    per_instance = tf.where(is_nans,\n",
    "                            tf.zeros_like(y_actual),\n",
    "                            tf.square(tf.subtract(y_predicted, y_actual)))\n",
    "    print(stack)\n",
    "    print(per_instance)\n",
    "    return tf.reduce_mean(per_instance, axis=0)\n",
    "\n",
    "print(nan_mse([1.,1.,np.nan,1.,0.], [1.,1.,0.,0.,np.nan]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e02aa91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 Complete [00h 00m 11s]\n",
      "val_avg_multilabel_BA_2: 0.9099557995796204\n",
      "\n",
      "Best val_avg_multilabel_BA_2 So Far: 0.9160040020942688\n",
      "Total elapsed time: 00h 00m 11s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 6ms/step - loss: 0.3988 - avg_multilabel_BA_2: 0.9096 - val_loss: 0.1177 - val_avg_multilabel_BA_2: 0.9096\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1009 - avg_multilabel_BA_2: 0.9096 - val_loss: 0.1063 - val_avg_multilabel_BA_2: 0.9097\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0895 - avg_multilabel_BA_2: 0.9097 - val_loss: 0.0992 - val_avg_multilabel_BA_2: 0.9098\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0818 - avg_multilabel_BA_2: 0.9099 - val_loss: 0.1066 - val_avg_multilabel_BA_2: 0.9100\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0776 - avg_multilabel_BA_2: 0.9101 - val_loss: 0.0838 - val_avg_multilabel_BA_2: 0.9103\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0703 - avg_multilabel_BA_2: 0.9104 - val_loss: 0.0891 - val_avg_multilabel_BA_2: 0.9106\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0706 - avg_multilabel_BA_2: 0.9108 - val_loss: 0.0997 - val_avg_multilabel_BA_2: 0.9109\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0617 - avg_multilabel_BA_2: 0.9111 - val_loss: 0.0847 - val_avg_multilabel_BA_2: 0.9113\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0660 - avg_multilabel_BA_2: 0.9115 - val_loss: 0.0792 - val_avg_multilabel_BA_2: 0.9117\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0563 - avg_multilabel_BA_2: 0.9119 - val_loss: 0.0757 - val_avg_multilabel_BA_2: 0.9121\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0608 - avg_multilabel_BA_2: 0.9123 - val_loss: 0.0791 - val_avg_multilabel_BA_2: 0.9125\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0545 - avg_multilabel_BA_2: 0.9127 - val_loss: 0.0774 - val_avg_multilabel_BA_2: 0.9129\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0645 - avg_multilabel_BA_2: 0.9131 - val_loss: 0.0771 - val_avg_multilabel_BA_2: 0.9133\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0668 - avg_multilabel_BA_2: 0.9134 - val_loss: 0.0989 - val_avg_multilabel_BA_2: 0.9136\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0611 - avg_multilabel_BA_2: 0.9138 - val_loss: 0.1389 - val_avg_multilabel_BA_2: 0.9139\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0551 - avg_multilabel_BA_2: 0.9141 - val_loss: 0.0683 - val_avg_multilabel_BA_2: 0.9143\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0500 - avg_multilabel_BA_2: 0.9145 - val_loss: 0.0915 - val_avg_multilabel_BA_2: 0.9147\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0545 - avg_multilabel_BA_2: 0.9149 - val_loss: 0.0878 - val_avg_multilabel_BA_2: 0.9150\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0496 - avg_multilabel_BA_2: 0.9153 - val_loss: 0.0742 - val_avg_multilabel_BA_2: 0.9154\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0499 - avg_multilabel_BA_2: 0.9156 - val_loss: 0.0849 - val_avg_multilabel_BA_2: 0.9158\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0458 - avg_multilabel_BA_2: 0.9160 - val_loss: 0.0749 - val_avg_multilabel_BA_2: 0.9162\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0493 - avg_multilabel_BA_2: 0.9163 - val_loss: 0.0845 - val_avg_multilabel_BA_2: 0.9165\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0592 - avg_multilabel_BA_2: 0.9167 - val_loss: 0.0848 - val_avg_multilabel_BA_2: 0.9168\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0531 - avg_multilabel_BA_2: 0.9170 - val_loss: 0.0783 - val_avg_multilabel_BA_2: 0.9172\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0464 - avg_multilabel_BA_2: 0.9173 - val_loss: 0.0856 - val_avg_multilabel_BA_2: 0.9175\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0487 - avg_multilabel_BA_2: 0.9177 - val_loss: 0.0945 - val_avg_multilabel_BA_2: 0.9179\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0475 - avg_multilabel_BA_2: 0.9180 - val_loss: 0.0770 - val_avg_multilabel_BA_2: 0.9182\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0453 - avg_multilabel_BA_2: 0.9184 - val_loss: 0.0849 - val_avg_multilabel_BA_2: 0.9185\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0477 - avg_multilabel_BA_2: 0.9187 - val_loss: 0.1138 - val_avg_multilabel_BA_2: 0.9189\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0548 - avg_multilabel_BA_2: 0.9189 - val_loss: 0.0864 - val_avg_multilabel_BA_2: 0.9191\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0513 - avg_multilabel_BA_2: 0.9192 - val_loss: 0.1050 - val_avg_multilabel_BA_2: 0.9194\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0771 - avg_multilabel_BA_2: 0.9195 - val_loss: 0.0901 - val_avg_multilabel_BA_2: 0.9196\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0818 - avg_multilabel_BA_2: 0.9196 - val_loss: 0.0980 - val_avg_multilabel_BA_2: 0.9197\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0641 - avg_multilabel_BA_2: 0.9198 - val_loss: 0.0903 - val_avg_multilabel_BA_2: 0.9200\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0582 - avg_multilabel_BA_2: 0.9201 - val_loss: 0.0795 - val_avg_multilabel_BA_2: 0.9202\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0578 - avg_multilabel_BA_2: 0.9203 - val_loss: 0.0886 - val_avg_multilabel_BA_2: 0.9205\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0586 - avg_multilabel_BA_2: 0.9206 - val_loss: 0.1031 - val_avg_multilabel_BA_2: 0.9207\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0692 - avg_multilabel_BA_2: 0.9209 - val_loss: 0.0925 - val_avg_multilabel_BA_2: 0.9210\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0647 - avg_multilabel_BA_2: 0.9211 - val_loss: 0.0801 - val_avg_multilabel_BA_2: 0.9212\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0610 - avg_multilabel_BA_2: 0.9213 - val_loss: 0.0840 - val_avg_multilabel_BA_2: 0.9214\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0472 - avg_multilabel_BA_2: 0.9216 - val_loss: 0.0762 - val_avg_multilabel_BA_2: 0.9217\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0570 - avg_multilabel_BA_2: 0.9219 - val_loss: 0.0764 - val_avg_multilabel_BA_2: 0.9220\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0556 - avg_multilabel_BA_2: 0.9221 - val_loss: 0.0906 - val_avg_multilabel_BA_2: 0.9222\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0586 - avg_multilabel_BA_2: 0.9224 - val_loss: 0.0784 - val_avg_multilabel_BA_2: 0.9225\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0498 - avg_multilabel_BA_2: 0.9226 - val_loss: 0.0994 - val_avg_multilabel_BA_2: 0.9227\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0699 - avg_multilabel_BA_2: 0.9228 - val_loss: 0.0887 - val_avg_multilabel_BA_2: 0.9229\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0515 - avg_multilabel_BA_2: 0.9230 - val_loss: 0.0758 - val_avg_multilabel_BA_2: 0.9232\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0541 - avg_multilabel_BA_2: 0.9233 - val_loss: 0.0702 - val_avg_multilabel_BA_2: 0.9234\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0588 - avg_multilabel_BA_2: 0.9236 - val_loss: 0.1568 - val_avg_multilabel_BA_2: 0.9236\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0627 - avg_multilabel_BA_2: 0.9237 - val_loss: 0.0914 - val_avg_multilabel_BA_2: 0.9238\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0612 - avg_multilabel_BA_2: 0.9239 - val_loss: 0.0839 - val_avg_multilabel_BA_2: 0.9240\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0635 - avg_multilabel_BA_2: 0.9240 - val_loss: 0.0691 - val_avg_multilabel_BA_2: 0.9240\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0529 - avg_multilabel_BA_2: 0.9242 - val_loss: 0.0789 - val_avg_multilabel_BA_2: 0.9243\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0485 - avg_multilabel_BA_2: 0.9244 - val_loss: 0.0788 - val_avg_multilabel_BA_2: 0.9245\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0461 - avg_multilabel_BA_2: 0.9247 - val_loss: 0.0955 - val_avg_multilabel_BA_2: 0.9248\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0487 - avg_multilabel_BA_2: 0.9249 - val_loss: 0.1193 - val_avg_multilabel_BA_2: 0.9250\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0487 - avg_multilabel_BA_2: 0.9252 - val_loss: 0.0798 - val_avg_multilabel_BA_2: 0.9253\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0453 - avg_multilabel_BA_2: 0.9254 - val_loss: 0.0919 - val_avg_multilabel_BA_2: 0.9255\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0492 - avg_multilabel_BA_2: 0.9256 - val_loss: 0.0887 - val_avg_multilabel_BA_2: 0.9258\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0457 - avg_multilabel_BA_2: 0.9259 - val_loss: 0.0794 - val_avg_multilabel_BA_2: 0.9260\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0477 - avg_multilabel_BA_2: 0.9261 - val_loss: 0.0997 - val_avg_multilabel_BA_2: 0.9262\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0482 - avg_multilabel_BA_2: 0.9264 - val_loss: 0.0696 - val_avg_multilabel_BA_2: 0.9265\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0548 - avg_multilabel_BA_2: 0.9266 - val_loss: 0.0927 - val_avg_multilabel_BA_2: 0.9267\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0580 - avg_multilabel_BA_2: 0.9268 - val_loss: 0.0772 - val_avg_multilabel_BA_2: 0.9269\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0655 - avg_multilabel_BA_2: 0.9269 - val_loss: 0.0710 - val_avg_multilabel_BA_2: 0.9270\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0636 - avg_multilabel_BA_2: 0.9271 - val_loss: 0.0959 - val_avg_multilabel_BA_2: 0.9272\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0489 - avg_multilabel_BA_2: 0.9273 - val_loss: 0.0926 - val_avg_multilabel_BA_2: 0.9274\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0481 - avg_multilabel_BA_2: 0.9275 - val_loss: 0.0845 - val_avg_multilabel_BA_2: 0.9277\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0511 - avg_multilabel_BA_2: 0.9277 - val_loss: 0.0832 - val_avg_multilabel_BA_2: 0.9279\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0462 - avg_multilabel_BA_2: 0.9280 - val_loss: 0.0856 - val_avg_multilabel_BA_2: 0.9281\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0465 - avg_multilabel_BA_2: 0.9282 - val_loss: 0.0995 - val_avg_multilabel_BA_2: 0.9283\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0537 - avg_multilabel_BA_2: 0.9284 - val_loss: 0.0775 - val_avg_multilabel_BA_2: 0.9285\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0412 - avg_multilabel_BA_2: 0.9286 - val_loss: 0.0887 - val_avg_multilabel_BA_2: 0.9287\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0478 - avg_multilabel_BA_2: 0.9288 - val_loss: 0.1466 - val_avg_multilabel_BA_2: 0.9289\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0493 - avg_multilabel_BA_2: 0.9290 - val_loss: 0.0834 - val_avg_multilabel_BA_2: 0.9291\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0428 - avg_multilabel_BA_2: 0.9292 - val_loss: 0.0751 - val_avg_multilabel_BA_2: 0.9293\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0447 - avg_multilabel_BA_2: 0.9294 - val_loss: 0.0733 - val_avg_multilabel_BA_2: 0.9295\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0443 - avg_multilabel_BA_2: 0.9296 - val_loss: 0.1159 - val_avg_multilabel_BA_2: 0.9297\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0524 - avg_multilabel_BA_2: 0.9298 - val_loss: 0.0714 - val_avg_multilabel_BA_2: 0.9299\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0665 - avg_multilabel_BA_2: 0.9300 - val_loss: 0.1360 - val_avg_multilabel_BA_2: 0.9300\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0815 - avg_multilabel_BA_2: 0.9301 - val_loss: 0.1116 - val_avg_multilabel_BA_2: 0.9301\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0516 - avg_multilabel_BA_2: 0.9301 - val_loss: 0.0895 - val_avg_multilabel_BA_2: 0.9302\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0454 - avg_multilabel_BA_2: 0.9303 - val_loss: 0.0745 - val_avg_multilabel_BA_2: 0.9304\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0480 - avg_multilabel_BA_2: 0.9305 - val_loss: 0.0751 - val_avg_multilabel_BA_2: 0.9306\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0500 - avg_multilabel_BA_2: 0.9307 - val_loss: 0.0838 - val_avg_multilabel_BA_2: 0.9308\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0429 - avg_multilabel_BA_2: 0.9309 - val_loss: 0.1322 - val_avg_multilabel_BA_2: 0.9310\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0461 - avg_multilabel_BA_2: 0.9310 - val_loss: 0.0793 - val_avg_multilabel_BA_2: 0.9311\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0457 - avg_multilabel_BA_2: 0.9312 - val_loss: 0.0772 - val_avg_multilabel_BA_2: 0.9313\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0455 - avg_multilabel_BA_2: 0.9314 - val_loss: 0.0722 - val_avg_multilabel_BA_2: 0.9315\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0476 - avg_multilabel_BA_2: 0.9316 - val_loss: 0.0867 - val_avg_multilabel_BA_2: 0.9317\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0444 - avg_multilabel_BA_2: 0.9318 - val_loss: 0.0792 - val_avg_multilabel_BA_2: 0.9319\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0469 - avg_multilabel_BA_2: 0.9319 - val_loss: 0.0737 - val_avg_multilabel_BA_2: 0.9320\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0426 - avg_multilabel_BA_2: 0.9321 - val_loss: 0.0835 - val_avg_multilabel_BA_2: 0.9322\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0589 - avg_multilabel_BA_2: 0.9323 - val_loss: 0.1767 - val_avg_multilabel_BA_2: 0.9324\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0603 - avg_multilabel_BA_2: 0.9324 - val_loss: 0.1006 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0694 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.1424 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0623 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.1639 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0711 - avg_multilabel_BA_2: 0.9326 - val_loss: 0.0924 - val_avg_multilabel_BA_2: 0.9326\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0566 - avg_multilabel_BA_2: 0.9326 - val_loss: 0.0888 - val_avg_multilabel_BA_2: 0.9327\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0499 - avg_multilabel_BA_2: 0.9328 - val_loss: 0.0993 - val_avg_multilabel_BA_2: 0.9328\n",
      "Best epoch: 100\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 6ms/step - loss: 0.3824 - avg_multilabel_BA_2: 0.9326 - val_loss: 0.1296 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0980 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.0995 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0869 - avg_multilabel_BA_2: 0.9324 - val_loss: 0.0936 - val_avg_multilabel_BA_2: 0.9324\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0883 - avg_multilabel_BA_2: 0.9324 - val_loss: 0.0839 - val_avg_multilabel_BA_2: 0.9324\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0760 - avg_multilabel_BA_2: 0.9324 - val_loss: 0.0949 - val_avg_multilabel_BA_2: 0.9324\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0701 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.0747 - val_avg_multilabel_BA_2: 0.9325\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0642 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.0742 - val_avg_multilabel_BA_2: 0.9326\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0616 - avg_multilabel_BA_2: 0.9326 - val_loss: 0.0719 - val_avg_multilabel_BA_2: 0.9327\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0629 - avg_multilabel_BA_2: 0.9327 - val_loss: 0.0909 - val_avg_multilabel_BA_2: 0.9328\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0607 - avg_multilabel_BA_2: 0.9328 - val_loss: 0.0777 - val_avg_multilabel_BA_2: 0.9329\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0609 - avg_multilabel_BA_2: 0.9329 - val_loss: 0.0795 - val_avg_multilabel_BA_2: 0.9330\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0581 - avg_multilabel_BA_2: 0.9330 - val_loss: 0.1017 - val_avg_multilabel_BA_2: 0.9331\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0611 - avg_multilabel_BA_2: 0.9331 - val_loss: 0.0836 - val_avg_multilabel_BA_2: 0.9332\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0688 - avg_multilabel_BA_2: 0.9332 - val_loss: 0.0809 - val_avg_multilabel_BA_2: 0.9332\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0576 - avg_multilabel_BA_2: 0.9333 - val_loss: 0.1152 - val_avg_multilabel_BA_2: 0.9333\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0554 - avg_multilabel_BA_2: 0.9334 - val_loss: 0.0685 - val_avg_multilabel_BA_2: 0.9334\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0498 - avg_multilabel_BA_2: 0.9335 - val_loss: 0.0780 - val_avg_multilabel_BA_2: 0.9336\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0548 - avg_multilabel_BA_2: 0.9336 - val_loss: 0.0819 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0959 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.1133 - val_avg_multilabel_BA_2: 0.9336\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0839 - avg_multilabel_BA_2: 0.9336 - val_loss: 0.0910 - val_avg_multilabel_BA_2: 0.9336\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0687 - avg_multilabel_BA_2: 0.9336 - val_loss: 0.1113 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0730 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.0856 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0670 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.0912 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0742 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.0963 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0652 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.0980 - val_avg_multilabel_BA_2: 0.9338\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0625 - avg_multilabel_BA_2: 0.9338 - val_loss: 0.0917 - val_avg_multilabel_BA_2: 0.9338\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0637 - avg_multilabel_BA_2: 0.9338 - val_loss: 0.1034 - val_avg_multilabel_BA_2: 0.9339\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0614 - avg_multilabel_BA_2: 0.9339 - val_loss: 0.1046 - val_avg_multilabel_BA_2: 0.9339\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0585 - avg_multilabel_BA_2: 0.9339 - val_loss: 0.0837 - val_avg_multilabel_BA_2: 0.9340\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0700 - avg_multilabel_BA_2: 0.9340 - val_loss: 0.0884 - val_avg_multilabel_BA_2: 0.9340\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0501 - avg_multilabel_BA_2: 0.9341 - val_loss: 0.0963 - val_avg_multilabel_BA_2: 0.9341\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0537 - avg_multilabel_BA_2: 0.9342 - val_loss: 0.0709 - val_avg_multilabel_BA_2: 0.9342\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0656 - avg_multilabel_BA_2: 0.9342 - val_loss: 0.0954 - val_avg_multilabel_BA_2: 0.9343\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0553 - avg_multilabel_BA_2: 0.9343 - val_loss: 0.0824 - val_avg_multilabel_BA_2: 0.9344\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0558 - avg_multilabel_BA_2: 0.9344 - val_loss: 0.1724 - val_avg_multilabel_BA_2: 0.9344\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0599 - avg_multilabel_BA_2: 0.9345 - val_loss: 0.0987 - val_avg_multilabel_BA_2: 0.9345\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0562 - avg_multilabel_BA_2: 0.9345 - val_loss: 0.0683 - val_avg_multilabel_BA_2: 0.9346\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0664 - avg_multilabel_BA_2: 0.9346 - val_loss: 0.0865 - val_avg_multilabel_BA_2: 0.9346\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0544 - avg_multilabel_BA_2: 0.9347 - val_loss: 0.0822 - val_avg_multilabel_BA_2: 0.9347\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0513 - avg_multilabel_BA_2: 0.9348 - val_loss: 0.0997 - val_avg_multilabel_BA_2: 0.9348\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0556 - avg_multilabel_BA_2: 0.9348 - val_loss: 0.0875 - val_avg_multilabel_BA_2: 0.9349\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0459 - avg_multilabel_BA_2: 0.9349 - val_loss: 0.0883 - val_avg_multilabel_BA_2: 0.9350\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0581 - avg_multilabel_BA_2: 0.9350 - val_loss: 0.0782 - val_avg_multilabel_BA_2: 0.9351\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0481 - avg_multilabel_BA_2: 0.9351 - val_loss: 0.0694 - val_avg_multilabel_BA_2: 0.9352\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0411 - avg_multilabel_BA_2: 0.9352 - val_loss: 0.0702 - val_avg_multilabel_BA_2: 0.9353\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0480 - avg_multilabel_BA_2: 0.9353 - val_loss: 0.0917 - val_avg_multilabel_BA_2: 0.9354\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0520 - avg_multilabel_BA_2: 0.9354 - val_loss: 0.0765 - val_avg_multilabel_BA_2: 0.9354\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0487 - avg_multilabel_BA_2: 0.9355 - val_loss: 0.1030 - val_avg_multilabel_BA_2: 0.9355\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0630 - avg_multilabel_BA_2: 0.9356 - val_loss: 0.0748 - val_avg_multilabel_BA_2: 0.9356\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0508 - avg_multilabel_BA_2: 0.9356 - val_loss: 0.0715 - val_avg_multilabel_BA_2: 0.9357\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0425 - avg_multilabel_BA_2: 0.9357 - val_loss: 0.0778 - val_avg_multilabel_BA_2: 0.9358\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0415 - avg_multilabel_BA_2: 0.9358 - val_loss: 0.0699 - val_avg_multilabel_BA_2: 0.9359\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0444 - avg_multilabel_BA_2: 0.9359 - val_loss: 0.1749 - val_avg_multilabel_BA_2: 0.9360\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0672 - avg_multilabel_BA_2: 0.9360 - val_loss: 0.1002 - val_avg_multilabel_BA_2: 0.9360\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0421 - avg_multilabel_BA_2: 0.9360 - val_loss: 0.0805 - val_avg_multilabel_BA_2: 0.9361\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0447 - avg_multilabel_BA_2: 0.9362 - val_loss: 0.0656 - val_avg_multilabel_BA_2: 0.9362\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0385 - avg_multilabel_BA_2: 0.9363 - val_loss: 0.0786 - val_avg_multilabel_BA_2: 0.9363\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0474 - avg_multilabel_BA_2: 0.9363 - val_loss: 0.1134 - val_avg_multilabel_BA_2: 0.9364\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0478 - avg_multilabel_BA_2: 0.9364 - val_loss: 0.0766 - val_avg_multilabel_BA_2: 0.9365\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0407 - avg_multilabel_BA_2: 0.9365 - val_loss: 0.0721 - val_avg_multilabel_BA_2: 0.9366\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0695 - avg_multilabel_BA_2: 0.9366 - val_loss: 0.1088 - val_avg_multilabel_BA_2: 0.9366\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0531 - avg_multilabel_BA_2: 0.9366 - val_loss: 0.0803 - val_avg_multilabel_BA_2: 0.9367\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0470 - avg_multilabel_BA_2: 0.9367 - val_loss: 0.0841 - val_avg_multilabel_BA_2: 0.9368\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0554 - avg_multilabel_BA_2: 0.9368 - val_loss: 0.0855 - val_avg_multilabel_BA_2: 0.9369\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0570 - avg_multilabel_BA_2: 0.9369 - val_loss: 0.0772 - val_avg_multilabel_BA_2: 0.9370\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0554 - avg_multilabel_BA_2: 0.9370 - val_loss: 0.1018 - val_avg_multilabel_BA_2: 0.9370\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0568 - avg_multilabel_BA_2: 0.9371 - val_loss: 0.0854 - val_avg_multilabel_BA_2: 0.9371\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0557 - avg_multilabel_BA_2: 0.9372 - val_loss: 0.0823 - val_avg_multilabel_BA_2: 0.9372\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0485 - avg_multilabel_BA_2: 0.9373 - val_loss: 0.0692 - val_avg_multilabel_BA_2: 0.9373\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0434 - avg_multilabel_BA_2: 0.9374 - val_loss: 0.0793 - val_avg_multilabel_BA_2: 0.9374\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0441 - avg_multilabel_BA_2: 0.9375 - val_loss: 0.0720 - val_avg_multilabel_BA_2: 0.9375\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0436 - avg_multilabel_BA_2: 0.9376 - val_loss: 0.0795 - val_avg_multilabel_BA_2: 0.9376\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0475 - avg_multilabel_BA_2: 0.9377 - val_loss: 0.0805 - val_avg_multilabel_BA_2: 0.9377\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0452 - avg_multilabel_BA_2: 0.9378 - val_loss: 0.0784 - val_avg_multilabel_BA_2: 0.9378\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0397 - avg_multilabel_BA_2: 0.9379 - val_loss: 0.0814 - val_avg_multilabel_BA_2: 0.9379\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0392 - avg_multilabel_BA_2: 0.9380 - val_loss: 0.0751 - val_avg_multilabel_BA_2: 0.9380\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0363 - avg_multilabel_BA_2: 0.9381 - val_loss: 0.0777 - val_avg_multilabel_BA_2: 0.9381\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0360 - avg_multilabel_BA_2: 0.9382 - val_loss: 0.1005 - val_avg_multilabel_BA_2: 0.9382\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0447 - avg_multilabel_BA_2: 0.9382 - val_loss: 0.0836 - val_avg_multilabel_BA_2: 0.9383\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0498 - avg_multilabel_BA_2: 0.9383 - val_loss: 0.1060 - val_avg_multilabel_BA_2: 0.9383\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0564 - avg_multilabel_BA_2: 0.9384 - val_loss: 0.0705 - val_avg_multilabel_BA_2: 0.9384\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0593 - avg_multilabel_BA_2: 0.9384 - val_loss: 0.0818 - val_avg_multilabel_BA_2: 0.9385\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0520 - avg_multilabel_BA_2: 0.9385 - val_loss: 0.0825 - val_avg_multilabel_BA_2: 0.9386\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0588 - avg_multilabel_BA_2: 0.9386 - val_loss: 0.0836 - val_avg_multilabel_BA_2: 0.9386\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0528 - avg_multilabel_BA_2: 0.9387 - val_loss: 0.0841 - val_avg_multilabel_BA_2: 0.9387\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0420 - avg_multilabel_BA_2: 0.9388 - val_loss: 0.0726 - val_avg_multilabel_BA_2: 0.9388\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0472 - avg_multilabel_BA_2: 0.9389 - val_loss: 0.0880 - val_avg_multilabel_BA_2: 0.9389\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0452 - avg_multilabel_BA_2: 0.9389 - val_loss: 0.0852 - val_avg_multilabel_BA_2: 0.9390\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0439 - avg_multilabel_BA_2: 0.9390 - val_loss: 0.0728 - val_avg_multilabel_BA_2: 0.9391\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0406 - avg_multilabel_BA_2: 0.9391 - val_loss: 0.0777 - val_avg_multilabel_BA_2: 0.9392\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0587 - avg_multilabel_BA_2: 0.9392 - val_loss: 0.0867 - val_avg_multilabel_BA_2: 0.9392\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0502 - avg_multilabel_BA_2: 0.9393 - val_loss: 0.0882 - val_avg_multilabel_BA_2: 0.9393\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0602 - avg_multilabel_BA_2: 0.9393 - val_loss: 0.1961 - val_avg_multilabel_BA_2: 0.9394\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1018 - avg_multilabel_BA_2: 0.9393 - val_loss: 0.1142 - val_avg_multilabel_BA_2: 0.9393\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0690 - avg_multilabel_BA_2: 0.9393 - val_loss: 0.0924 - val_avg_multilabel_BA_2: 0.9392\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0724 - avg_multilabel_BA_2: 0.9392 - val_loss: 0.0957 - val_avg_multilabel_BA_2: 0.9392\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0697 - avg_multilabel_BA_2: 0.9391 - val_loss: 0.0974 - val_avg_multilabel_BA_2: 0.9391\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0792 - avg_multilabel_BA_2: 0.9390 - val_loss: 0.0862 - val_avg_multilabel_BA_2: 0.9390\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0711 - avg_multilabel_BA_2: 0.9390 - val_loss: 0.0952 - val_avg_multilabel_BA_2: 0.9389\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0700 - avg_multilabel_BA_2: 0.9389 - val_loss: 0.1079 - val_avg_multilabel_BA_2: 0.9389\n",
      "25/25 [==============================] - 0s 513us/step - loss: 1.6926\n",
      "25/25 [==============================] - 0s 434us/step\n",
      "Test results - Loss - Accuracy: 1.692635178565979\n",
      "Averaged Balanced Accuracy: 0.938497\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "INFO:tensorflow:Reloading Oracle from existing project hypertunning/experimento_1_RandSearchCV/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hypertunning/experimento_1_RandSearchCV/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.5255 - avg_multilabel_BA_2: 0.9382 - val_loss: 0.2210 - val_avg_multilabel_BA_2: 0.9379\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2083 - avg_multilabel_BA_2: 0.9377 - val_loss: 0.1936 - val_avg_multilabel_BA_2: 0.9375\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1870 - avg_multilabel_BA_2: 0.9373 - val_loss: 0.1964 - val_avg_multilabel_BA_2: 0.9371\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1792 - avg_multilabel_BA_2: 0.9369 - val_loss: 0.1749 - val_avg_multilabel_BA_2: 0.9368\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1651 - avg_multilabel_BA_2: 0.9366 - val_loss: 0.1535 - val_avg_multilabel_BA_2: 0.9365\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1503 - avg_multilabel_BA_2: 0.9363 - val_loss: 0.1552 - val_avg_multilabel_BA_2: 0.9362\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1442 - avg_multilabel_BA_2: 0.9361 - val_loss: 0.1409 - val_avg_multilabel_BA_2: 0.9360\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1331 - avg_multilabel_BA_2: 0.9359 - val_loss: 0.1362 - val_avg_multilabel_BA_2: 0.9358\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1256 - avg_multilabel_BA_2: 0.9357 - val_loss: 0.1529 - val_avg_multilabel_BA_2: 0.9356\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1307 - avg_multilabel_BA_2: 0.9355 - val_loss: 0.1241 - val_avg_multilabel_BA_2: 0.9354\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1250 - avg_multilabel_BA_2: 0.9353 - val_loss: 0.1523 - val_avg_multilabel_BA_2: 0.9352\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1400 - avg_multilabel_BA_2: 0.9351 - val_loss: 0.1291 - val_avg_multilabel_BA_2: 0.9350\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1321 - avg_multilabel_BA_2: 0.9350 - val_loss: 0.1284 - val_avg_multilabel_BA_2: 0.9349\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1269 - avg_multilabel_BA_2: 0.9348 - val_loss: 0.1450 - val_avg_multilabel_BA_2: 0.9347\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1210 - avg_multilabel_BA_2: 0.9347 - val_loss: 0.1399 - val_avg_multilabel_BA_2: 0.9346\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1177 - avg_multilabel_BA_2: 0.9345 - val_loss: 0.1346 - val_avg_multilabel_BA_2: 0.9344\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1151 - avg_multilabel_BA_2: 0.9344 - val_loss: 0.1194 - val_avg_multilabel_BA_2: 0.9343\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1145 - avg_multilabel_BA_2: 0.9343 - val_loss: 0.1243 - val_avg_multilabel_BA_2: 0.9342\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1084 - avg_multilabel_BA_2: 0.9341 - val_loss: 0.1206 - val_avg_multilabel_BA_2: 0.9341\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1069 - avg_multilabel_BA_2: 0.9340 - val_loss: 0.1426 - val_avg_multilabel_BA_2: 0.9340\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1137 - avg_multilabel_BA_2: 0.9339 - val_loss: 0.1377 - val_avg_multilabel_BA_2: 0.9338\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1100 - avg_multilabel_BA_2: 0.9338 - val_loss: 0.1251 - val_avg_multilabel_BA_2: 0.9337\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1077 - avg_multilabel_BA_2: 0.9337 - val_loss: 0.1188 - val_avg_multilabel_BA_2: 0.9336\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1063 - avg_multilabel_BA_2: 0.9336 - val_loss: 0.1381 - val_avg_multilabel_BA_2: 0.9335\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1100 - avg_multilabel_BA_2: 0.9335 - val_loss: 0.1313 - val_avg_multilabel_BA_2: 0.9334\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1082 - avg_multilabel_BA_2: 0.9334 - val_loss: 0.1390 - val_avg_multilabel_BA_2: 0.9333\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1070 - avg_multilabel_BA_2: 0.9333 - val_loss: 0.1263 - val_avg_multilabel_BA_2: 0.9332\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1088 - avg_multilabel_BA_2: 0.9332 - val_loss: 0.1338 - val_avg_multilabel_BA_2: 0.9331\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1189 - avg_multilabel_BA_2: 0.9331 - val_loss: 0.1512 - val_avg_multilabel_BA_2: 0.9330\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1862 - avg_multilabel_BA_2: 0.9329 - val_loss: 0.1966 - val_avg_multilabel_BA_2: 0.9327\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1744 - avg_multilabel_BA_2: 0.9325 - val_loss: 0.1773 - val_avg_multilabel_BA_2: 0.9324\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1444 - avg_multilabel_BA_2: 0.9322 - val_loss: 0.1517 - val_avg_multilabel_BA_2: 0.9321\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1277 - avg_multilabel_BA_2: 0.9321 - val_loss: 0.1240 - val_avg_multilabel_BA_2: 0.9320\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1165 - avg_multilabel_BA_2: 0.9319 - val_loss: 0.1257 - val_avg_multilabel_BA_2: 0.9319\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1111 - avg_multilabel_BA_2: 0.9318 - val_loss: 0.1240 - val_avg_multilabel_BA_2: 0.9318\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1103 - avg_multilabel_BA_2: 0.9317 - val_loss: 0.1279 - val_avg_multilabel_BA_2: 0.9317\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1104 - avg_multilabel_BA_2: 0.9316 - val_loss: 0.1305 - val_avg_multilabel_BA_2: 0.9316\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1010 - avg_multilabel_BA_2: 0.9316 - val_loss: 0.1249 - val_avg_multilabel_BA_2: 0.9315\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1056 - avg_multilabel_BA_2: 0.9315 - val_loss: 0.1929 - val_avg_multilabel_BA_2: 0.9314\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1102 - avg_multilabel_BA_2: 0.9314 - val_loss: 0.1253 - val_avg_multilabel_BA_2: 0.9313\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1149 - avg_multilabel_BA_2: 0.9313 - val_loss: 0.1524 - val_avg_multilabel_BA_2: 0.9312\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1016 - avg_multilabel_BA_2: 0.9312 - val_loss: 0.1264 - val_avg_multilabel_BA_2: 0.9311\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1000 - avg_multilabel_BA_2: 0.9311 - val_loss: 0.1468 - val_avg_multilabel_BA_2: 0.9310\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1068 - avg_multilabel_BA_2: 0.9310 - val_loss: 0.1273 - val_avg_multilabel_BA_2: 0.9310\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1009 - avg_multilabel_BA_2: 0.9309 - val_loss: 0.1329 - val_avg_multilabel_BA_2: 0.9309\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1032 - avg_multilabel_BA_2: 0.9308 - val_loss: 0.1300 - val_avg_multilabel_BA_2: 0.9308\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1088 - avg_multilabel_BA_2: 0.9307 - val_loss: 0.1351 - val_avg_multilabel_BA_2: 0.9307\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1020 - avg_multilabel_BA_2: 0.9307 - val_loss: 0.1330 - val_avg_multilabel_BA_2: 0.9306\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0997 - avg_multilabel_BA_2: 0.9306 - val_loss: 0.1259 - val_avg_multilabel_BA_2: 0.9306\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1102 - avg_multilabel_BA_2: 0.9305 - val_loss: 0.1353 - val_avg_multilabel_BA_2: 0.9305\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1044 - avg_multilabel_BA_2: 0.9304 - val_loss: 0.1419 - val_avg_multilabel_BA_2: 0.9304\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0989 - avg_multilabel_BA_2: 0.9303 - val_loss: 0.1406 - val_avg_multilabel_BA_2: 0.9303\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0977 - avg_multilabel_BA_2: 0.9303 - val_loss: 0.1753 - val_avg_multilabel_BA_2: 0.9302\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1024 - avg_multilabel_BA_2: 0.9302 - val_loss: 0.1443 - val_avg_multilabel_BA_2: 0.9302\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0999 - avg_multilabel_BA_2: 0.9301 - val_loss: 0.1305 - val_avg_multilabel_BA_2: 0.9301\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1134 - avg_multilabel_BA_2: 0.9301 - val_loss: 0.1332 - val_avg_multilabel_BA_2: 0.9300\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1020 - avg_multilabel_BA_2: 0.9300 - val_loss: 0.1316 - val_avg_multilabel_BA_2: 0.9299\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1001 - avg_multilabel_BA_2: 0.9299 - val_loss: 0.1347 - val_avg_multilabel_BA_2: 0.9299\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0997 - avg_multilabel_BA_2: 0.9298 - val_loss: 0.1296 - val_avg_multilabel_BA_2: 0.9298\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1085 - avg_multilabel_BA_2: 0.9298 - val_loss: 0.1413 - val_avg_multilabel_BA_2: 0.9297\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0989 - avg_multilabel_BA_2: 0.9297 - val_loss: 0.1376 - val_avg_multilabel_BA_2: 0.9297\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1021 - avg_multilabel_BA_2: 0.9296 - val_loss: 0.1289 - val_avg_multilabel_BA_2: 0.9296\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1070 - avg_multilabel_BA_2: 0.9295 - val_loss: 0.1380 - val_avg_multilabel_BA_2: 0.9295\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0995 - avg_multilabel_BA_2: 0.9295 - val_loss: 0.1410 - val_avg_multilabel_BA_2: 0.9294\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0985 - avg_multilabel_BA_2: 0.9294 - val_loss: 0.1419 - val_avg_multilabel_BA_2: 0.9294\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0961 - avg_multilabel_BA_2: 0.9293 - val_loss: 0.1374 - val_avg_multilabel_BA_2: 0.9293\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1015 - avg_multilabel_BA_2: 0.9293 - val_loss: 0.1438 - val_avg_multilabel_BA_2: 0.9292\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0937 - avg_multilabel_BA_2: 0.9292 - val_loss: 0.1356 - val_avg_multilabel_BA_2: 0.9292\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1034 - avg_multilabel_BA_2: 0.9291 - val_loss: 0.1289 - val_avg_multilabel_BA_2: 0.9291\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1038 - avg_multilabel_BA_2: 0.9291 - val_loss: 0.1307 - val_avg_multilabel_BA_2: 0.9290\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0995 - avg_multilabel_BA_2: 0.9290 - val_loss: 0.1473 - val_avg_multilabel_BA_2: 0.9290\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0986 - avg_multilabel_BA_2: 0.9289 - val_loss: 0.1489 - val_avg_multilabel_BA_2: 0.9289\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1007 - avg_multilabel_BA_2: 0.9289 - val_loss: 0.1360 - val_avg_multilabel_BA_2: 0.9288\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1012 - avg_multilabel_BA_2: 0.9288 - val_loss: 0.1370 - val_avg_multilabel_BA_2: 0.9287\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1085 - avg_multilabel_BA_2: 0.9287 - val_loss: 0.1343 - val_avg_multilabel_BA_2: 0.9287\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0976 - avg_multilabel_BA_2: 0.9286 - val_loss: 0.1388 - val_avg_multilabel_BA_2: 0.9286\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0969 - avg_multilabel_BA_2: 0.9286 - val_loss: 0.1364 - val_avg_multilabel_BA_2: 0.9285\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1039 - avg_multilabel_BA_2: 0.9285 - val_loss: 0.1896 - val_avg_multilabel_BA_2: 0.9284\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1042 - avg_multilabel_BA_2: 0.9284 - val_loss: 0.1258 - val_avg_multilabel_BA_2: 0.9284\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1024 - avg_multilabel_BA_2: 0.9283 - val_loss: 0.1449 - val_avg_multilabel_BA_2: 0.9283\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1065 - avg_multilabel_BA_2: 0.9283 - val_loss: 0.1409 - val_avg_multilabel_BA_2: 0.9282\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0963 - avg_multilabel_BA_2: 0.9282 - val_loss: 0.1364 - val_avg_multilabel_BA_2: 0.9282\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0968 - avg_multilabel_BA_2: 0.9281 - val_loss: 0.1356 - val_avg_multilabel_BA_2: 0.9281\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0979 - avg_multilabel_BA_2: 0.9281 - val_loss: 0.1340 - val_avg_multilabel_BA_2: 0.9280\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0965 - avg_multilabel_BA_2: 0.9280 - val_loss: 0.1331 - val_avg_multilabel_BA_2: 0.9280\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1385 - avg_multilabel_BA_2: 0.9279 - val_loss: 0.1456 - val_avg_multilabel_BA_2: 0.9279\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1192 - avg_multilabel_BA_2: 0.9278 - val_loss: 0.1562 - val_avg_multilabel_BA_2: 0.9278\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1007 - avg_multilabel_BA_2: 0.9278 - val_loss: 0.1503 - val_avg_multilabel_BA_2: 0.9277\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1014 - avg_multilabel_BA_2: 0.9277 - val_loss: 0.1319 - val_avg_multilabel_BA_2: 0.9277\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0974 - avg_multilabel_BA_2: 0.9276 - val_loss: 0.1320 - val_avg_multilabel_BA_2: 0.9276\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1069 - avg_multilabel_BA_2: 0.9276 - val_loss: 0.1839 - val_avg_multilabel_BA_2: 0.9275\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1075 - avg_multilabel_BA_2: 0.9275 - val_loss: 0.1311 - val_avg_multilabel_BA_2: 0.9275\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0937 - avg_multilabel_BA_2: 0.9274 - val_loss: 0.1417 - val_avg_multilabel_BA_2: 0.9274\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0894 - avg_multilabel_BA_2: 0.9274 - val_loss: 0.1633 - val_avg_multilabel_BA_2: 0.9274\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0977 - avg_multilabel_BA_2: 0.9273 - val_loss: 0.1421 - val_avg_multilabel_BA_2: 0.9273\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0957 - avg_multilabel_BA_2: 0.9273 - val_loss: 0.1401 - val_avg_multilabel_BA_2: 0.9273\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0948 - avg_multilabel_BA_2: 0.9272 - val_loss: 0.1396 - val_avg_multilabel_BA_2: 0.9272\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0956 - avg_multilabel_BA_2: 0.9272 - val_loss: 0.1385 - val_avg_multilabel_BA_2: 0.9272\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0922 - avg_multilabel_BA_2: 0.9271 - val_loss: 0.1340 - val_avg_multilabel_BA_2: 0.9271\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0953 - avg_multilabel_BA_2: 0.9271 - val_loss: 0.1774 - val_avg_multilabel_BA_2: 0.9271\n",
      "Best epoch: 1\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.5137 - avg_multilabel_BA_2: 0.9268 - val_loss: 0.2423 - val_avg_multilabel_BA_2: 0.9266\n",
      "20/20 [==============================] - 0s 651us/step - loss: 1.3204\n",
      "20/20 [==============================] - 0s 520us/step\n",
      "Test results - Loss - Accuracy: 1.3204219341278076\n",
      "Averaged Balanced Accuracy: 0.926355\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "INFO:tensorflow:Reloading Oracle from existing project hypertunning/experimento_1_RandSearchCV/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hypertunning/experimento_1_RandSearchCV/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.4771 - avg_multilabel_BA_2: 0.9261 - val_loss: 0.2153 - val_avg_multilabel_BA_2: 0.9259\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2010 - avg_multilabel_BA_2: 0.9258 - val_loss: 0.1749 - val_avg_multilabel_BA_2: 0.9256\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1748 - avg_multilabel_BA_2: 0.9255 - val_loss: 0.1568 - val_avg_multilabel_BA_2: 0.9254\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1616 - avg_multilabel_BA_2: 0.9252 - val_loss: 0.1492 - val_avg_multilabel_BA_2: 0.9251\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1528 - avg_multilabel_BA_2: 0.9250 - val_loss: 0.1429 - val_avg_multilabel_BA_2: 0.9249\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1500 - avg_multilabel_BA_2: 0.9248 - val_loss: 0.1544 - val_avg_multilabel_BA_2: 0.9247\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1475 - avg_multilabel_BA_2: 0.9246 - val_loss: 0.1368 - val_avg_multilabel_BA_2: 0.9245\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1394 - avg_multilabel_BA_2: 0.9245 - val_loss: 0.1334 - val_avg_multilabel_BA_2: 0.9244\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1441 - avg_multilabel_BA_2: 0.9243 - val_loss: 0.1698 - val_avg_multilabel_BA_2: 0.9242\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1433 - avg_multilabel_BA_2: 0.9242 - val_loss: 0.1318 - val_avg_multilabel_BA_2: 0.9241\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1275 - avg_multilabel_BA_2: 0.9241 - val_loss: 0.1239 - val_avg_multilabel_BA_2: 0.9240\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1232 - avg_multilabel_BA_2: 0.9240 - val_loss: 0.1634 - val_avg_multilabel_BA_2: 0.9239\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1424 - avg_multilabel_BA_2: 0.9238 - val_loss: 0.1880 - val_avg_multilabel_BA_2: 0.9237\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1456 - avg_multilabel_BA_2: 0.9236 - val_loss: 0.1379 - val_avg_multilabel_BA_2: 0.9235\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1246 - avg_multilabel_BA_2: 0.9235 - val_loss: 0.1410 - val_avg_multilabel_BA_2: 0.9234\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1263 - avg_multilabel_BA_2: 0.9234 - val_loss: 0.1582 - val_avg_multilabel_BA_2: 0.9233\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1272 - avg_multilabel_BA_2: 0.9233 - val_loss: 0.1388 - val_avg_multilabel_BA_2: 0.9232\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1217 - avg_multilabel_BA_2: 0.9231 - val_loss: 0.1531 - val_avg_multilabel_BA_2: 0.9231\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1229 - avg_multilabel_BA_2: 0.9230 - val_loss: 0.1395 - val_avg_multilabel_BA_2: 0.9230\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1269 - avg_multilabel_BA_2: 0.9229 - val_loss: 0.1409 - val_avg_multilabel_BA_2: 0.9229\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1329 - avg_multilabel_BA_2: 0.9228 - val_loss: 0.1537 - val_avg_multilabel_BA_2: 0.9228\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1216 - avg_multilabel_BA_2: 0.9227 - val_loss: 0.1590 - val_avg_multilabel_BA_2: 0.9227\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1271 - avg_multilabel_BA_2: 0.9226 - val_loss: 0.1338 - val_avg_multilabel_BA_2: 0.9226\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1223 - avg_multilabel_BA_2: 0.9225 - val_loss: 0.1399 - val_avg_multilabel_BA_2: 0.9225\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1294 - avg_multilabel_BA_2: 0.9224 - val_loss: 0.1471 - val_avg_multilabel_BA_2: 0.9224\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1314 - avg_multilabel_BA_2: 0.9223 - val_loss: 0.1582 - val_avg_multilabel_BA_2: 0.9222\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1257 - avg_multilabel_BA_2: 0.9222 - val_loss: 0.1330 - val_avg_multilabel_BA_2: 0.9221\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1159 - avg_multilabel_BA_2: 0.9221 - val_loss: 0.1333 - val_avg_multilabel_BA_2: 0.9221\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1186 - avg_multilabel_BA_2: 0.9220 - val_loss: 0.1392 - val_avg_multilabel_BA_2: 0.9220\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1131 - avg_multilabel_BA_2: 0.9219 - val_loss: 0.1301 - val_avg_multilabel_BA_2: 0.9219\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1144 - avg_multilabel_BA_2: 0.9218 - val_loss: 0.1337 - val_avg_multilabel_BA_2: 0.9218\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1061 - avg_multilabel_BA_2: 0.9218 - val_loss: 0.1570 - val_avg_multilabel_BA_2: 0.9217\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1163 - avg_multilabel_BA_2: 0.9217 - val_loss: 0.1759 - val_avg_multilabel_BA_2: 0.9216\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1336 - avg_multilabel_BA_2: 0.9216 - val_loss: 0.1345 - val_avg_multilabel_BA_2: 0.9215\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1337 - avg_multilabel_BA_2: 0.9215 - val_loss: 0.1383 - val_avg_multilabel_BA_2: 0.9214\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1145 - avg_multilabel_BA_2: 0.9214 - val_loss: 0.1303 - val_avg_multilabel_BA_2: 0.9213\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1134 - avg_multilabel_BA_2: 0.9213 - val_loss: 0.1263 - val_avg_multilabel_BA_2: 0.9213\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1095 - avg_multilabel_BA_2: 0.9212 - val_loss: 0.1296 - val_avg_multilabel_BA_2: 0.9212\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1085 - avg_multilabel_BA_2: 0.9211 - val_loss: 0.1495 - val_avg_multilabel_BA_2: 0.9211\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1057 - avg_multilabel_BA_2: 0.9211 - val_loss: 0.1357 - val_avg_multilabel_BA_2: 0.9210\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1052 - avg_multilabel_BA_2: 0.9210 - val_loss: 0.1317 - val_avg_multilabel_BA_2: 0.9210\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1142 - avg_multilabel_BA_2: 0.9210 - val_loss: 0.1232 - val_avg_multilabel_BA_2: 0.9209\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1215 - avg_multilabel_BA_2: 0.9209 - val_loss: 0.1408 - val_avg_multilabel_BA_2: 0.9208\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1025 - avg_multilabel_BA_2: 0.9208 - val_loss: 0.1356 - val_avg_multilabel_BA_2: 0.9208\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1218 - avg_multilabel_BA_2: 0.9207 - val_loss: 0.1736 - val_avg_multilabel_BA_2: 0.9207\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1109 - avg_multilabel_BA_2: 0.9206 - val_loss: 0.1367 - val_avg_multilabel_BA_2: 0.9206\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1082 - avg_multilabel_BA_2: 0.9206 - val_loss: 0.1228 - val_avg_multilabel_BA_2: 0.9205\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1044 - avg_multilabel_BA_2: 0.9205 - val_loss: 0.1530 - val_avg_multilabel_BA_2: 0.9205\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1045 - avg_multilabel_BA_2: 0.9204 - val_loss: 0.1403 - val_avg_multilabel_BA_2: 0.9204\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1076 - avg_multilabel_BA_2: 0.9204 - val_loss: 0.1251 - val_avg_multilabel_BA_2: 0.9204\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1075 - avg_multilabel_BA_2: 0.9203 - val_loss: 0.1277 - val_avg_multilabel_BA_2: 0.9203\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0988 - avg_multilabel_BA_2: 0.9203 - val_loss: 0.1369 - val_avg_multilabel_BA_2: 0.9203\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1007 - avg_multilabel_BA_2: 0.9202 - val_loss: 0.1269 - val_avg_multilabel_BA_2: 0.9202\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0974 - avg_multilabel_BA_2: 0.9202 - val_loss: 0.1426 - val_avg_multilabel_BA_2: 0.9202\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1013 - avg_multilabel_BA_2: 0.9202 - val_loss: 0.1324 - val_avg_multilabel_BA_2: 0.9201\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1093 - avg_multilabel_BA_2: 0.9201 - val_loss: 0.1354 - val_avg_multilabel_BA_2: 0.9201\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1025 - avg_multilabel_BA_2: 0.9201 - val_loss: 0.1385 - val_avg_multilabel_BA_2: 0.9200\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0996 - avg_multilabel_BA_2: 0.9200 - val_loss: 0.1487 - val_avg_multilabel_BA_2: 0.9200\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1151 - avg_multilabel_BA_2: 0.9200 - val_loss: 0.1506 - val_avg_multilabel_BA_2: 0.9199\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1187 - avg_multilabel_BA_2: 0.9199 - val_loss: 0.1328 - val_avg_multilabel_BA_2: 0.9198\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1007 - avg_multilabel_BA_2: 0.9198 - val_loss: 0.1387 - val_avg_multilabel_BA_2: 0.9198\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0988 - avg_multilabel_BA_2: 0.9198 - val_loss: 0.1323 - val_avg_multilabel_BA_2: 0.9197\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0999 - avg_multilabel_BA_2: 0.9197 - val_loss: 0.1404 - val_avg_multilabel_BA_2: 0.9197\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1159 - avg_multilabel_BA_2: 0.9197 - val_loss: 0.1358 - val_avg_multilabel_BA_2: 0.9197\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1017 - avg_multilabel_BA_2: 0.9196 - val_loss: 0.1389 - val_avg_multilabel_BA_2: 0.9196\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0977 - avg_multilabel_BA_2: 0.9196 - val_loss: 0.1338 - val_avg_multilabel_BA_2: 0.9196\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1000 - avg_multilabel_BA_2: 0.9195 - val_loss: 0.1364 - val_avg_multilabel_BA_2: 0.9195\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0936 - avg_multilabel_BA_2: 0.9195 - val_loss: 0.1405 - val_avg_multilabel_BA_2: 0.9195\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0981 - avg_multilabel_BA_2: 0.9195 - val_loss: 0.1451 - val_avg_multilabel_BA_2: 0.9195\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1288 - avg_multilabel_BA_2: 0.9194 - val_loss: 0.1650 - val_avg_multilabel_BA_2: 0.9193\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1316 - avg_multilabel_BA_2: 0.9192 - val_loss: 0.1399 - val_avg_multilabel_BA_2: 0.9191\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1257 - avg_multilabel_BA_2: 0.9190 - val_loss: 0.1593 - val_avg_multilabel_BA_2: 0.9189\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1301 - avg_multilabel_BA_2: 0.9188 - val_loss: 0.1559 - val_avg_multilabel_BA_2: 0.9187\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1333 - avg_multilabel_BA_2: 0.9186 - val_loss: 0.1426 - val_avg_multilabel_BA_2: 0.9185\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1294 - avg_multilabel_BA_2: 0.9184 - val_loss: 0.1745 - val_avg_multilabel_BA_2: 0.9183\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1292 - avg_multilabel_BA_2: 0.9182 - val_loss: 0.1590 - val_avg_multilabel_BA_2: 0.9181\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1251 - avg_multilabel_BA_2: 0.9180 - val_loss: 0.1449 - val_avg_multilabel_BA_2: 0.9179\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1271 - avg_multilabel_BA_2: 0.9178 - val_loss: 0.1517 - val_avg_multilabel_BA_2: 0.9177\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1225 - avg_multilabel_BA_2: 0.9176 - val_loss: 0.1546 - val_avg_multilabel_BA_2: 0.9175\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1289 - avg_multilabel_BA_2: 0.9174 - val_loss: 0.1454 - val_avg_multilabel_BA_2: 0.9173\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1312 - avg_multilabel_BA_2: 0.9172 - val_loss: 0.1474 - val_avg_multilabel_BA_2: 0.9171\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1276 - avg_multilabel_BA_2: 0.9170 - val_loss: 0.1540 - val_avg_multilabel_BA_2: 0.9169\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1283 - avg_multilabel_BA_2: 0.9168 - val_loss: 0.1566 - val_avg_multilabel_BA_2: 0.9167\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1319 - avg_multilabel_BA_2: 0.9166 - val_loss: 0.1701 - val_avg_multilabel_BA_2: 0.9165\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1341 - avg_multilabel_BA_2: 0.9164 - val_loss: 0.2601 - val_avg_multilabel_BA_2: 0.9163\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1326 - avg_multilabel_BA_2: 0.9162 - val_loss: 0.1481 - val_avg_multilabel_BA_2: 0.9161\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1241 - avg_multilabel_BA_2: 0.9160 - val_loss: 0.1494 - val_avg_multilabel_BA_2: 0.9159\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1253 - avg_multilabel_BA_2: 0.9158 - val_loss: 0.1465 - val_avg_multilabel_BA_2: 0.9157\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1282 - avg_multilabel_BA_2: 0.9156 - val_loss: 0.1524 - val_avg_multilabel_BA_2: 0.9155\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1256 - avg_multilabel_BA_2: 0.9154 - val_loss: 0.1519 - val_avg_multilabel_BA_2: 0.9153\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1266 - avg_multilabel_BA_2: 0.9152 - val_loss: 0.1536 - val_avg_multilabel_BA_2: 0.9151\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1239 - avg_multilabel_BA_2: 0.9150 - val_loss: 0.1492 - val_avg_multilabel_BA_2: 0.9149\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1254 - avg_multilabel_BA_2: 0.9149 - val_loss: 0.1506 - val_avg_multilabel_BA_2: 0.9148\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1229 - avg_multilabel_BA_2: 0.9147 - val_loss: 0.1489 - val_avg_multilabel_BA_2: 0.9146\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1293 - avg_multilabel_BA_2: 0.9145 - val_loss: 0.1531 - val_avg_multilabel_BA_2: 0.9144\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1288 - avg_multilabel_BA_2: 0.9143 - val_loss: 0.1668 - val_avg_multilabel_BA_2: 0.9142\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1253 - avg_multilabel_BA_2: 0.9141 - val_loss: 0.1554 - val_avg_multilabel_BA_2: 0.9140\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1416 - avg_multilabel_BA_2: 0.9139 - val_loss: 0.1758 - val_avg_multilabel_BA_2: 0.9138\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1368 - avg_multilabel_BA_2: 0.9137 - val_loss: 0.1623 - val_avg_multilabel_BA_2: 0.9136\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1274 - avg_multilabel_BA_2: 0.9135 - val_loss: 0.1552 - val_avg_multilabel_BA_2: 0.9134\n",
      "Best epoch: 1\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.5868 - avg_multilabel_BA_2: 0.9132 - val_loss: 0.2212 - val_avg_multilabel_BA_2: 0.9130\n",
      "20/20 [==============================] - 0s 597us/step - loss: 1.3499\n",
      "20/20 [==============================] - 0s 472us/step\n",
      "Test results - Loss - Accuracy: 1.3499153852462769\n",
      "Averaged Balanced Accuracy: 0.912855\n",
      "X train-test shape: (2486, 226) - X test shape: (622, 226)\n",
      "y train-test shape: (2486, 6) - y test shape: (622, 6)\n",
      "INFO:tensorflow:Reloading Oracle from existing project hypertunning/experimento_1_RandSearchCV/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hypertunning/experimento_1_RandSearchCV/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.4676 - avg_multilabel_BA_2: 0.9127 - val_loss: 0.2029 - val_avg_multilabel_BA_2: 0.9126\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1876 - avg_multilabel_BA_2: 0.9124 - val_loss: 0.1725 - val_avg_multilabel_BA_2: 0.9123\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1628 - avg_multilabel_BA_2: 0.9122 - val_loss: 0.1820 - val_avg_multilabel_BA_2: 0.9121\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1634 - avg_multilabel_BA_2: 0.9120 - val_loss: 0.1366 - val_avg_multilabel_BA_2: 0.9120\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1356 - avg_multilabel_BA_2: 0.9119 - val_loss: 0.1411 - val_avg_multilabel_BA_2: 0.9119\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1367 - avg_multilabel_BA_2: 0.9118 - val_loss: 0.1281 - val_avg_multilabel_BA_2: 0.9117\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1393 - avg_multilabel_BA_2: 0.9117 - val_loss: 0.1601 - val_avg_multilabel_BA_2: 0.9116\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1421 - avg_multilabel_BA_2: 0.9116 - val_loss: 0.1345 - val_avg_multilabel_BA_2: 0.9115\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1329 - avg_multilabel_BA_2: 0.9114 - val_loss: 0.1229 - val_avg_multilabel_BA_2: 0.9114\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1240 - avg_multilabel_BA_2: 0.9113 - val_loss: 0.1384 - val_avg_multilabel_BA_2: 0.9113\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1219 - avg_multilabel_BA_2: 0.9113 - val_loss: 0.1187 - val_avg_multilabel_BA_2: 0.9112\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1107 - avg_multilabel_BA_2: 0.9112 - val_loss: 0.1328 - val_avg_multilabel_BA_2: 0.9111\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1099 - avg_multilabel_BA_2: 0.9111 - val_loss: 0.1171 - val_avg_multilabel_BA_2: 0.9111\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1190 - avg_multilabel_BA_2: 0.9110 - val_loss: 0.1336 - val_avg_multilabel_BA_2: 0.9110\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1303 - avg_multilabel_BA_2: 0.9109 - val_loss: 0.1208 - val_avg_multilabel_BA_2: 0.9109\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1110 - avg_multilabel_BA_2: 0.9108 - val_loss: 0.1059 - val_avg_multilabel_BA_2: 0.9108\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1067 - avg_multilabel_BA_2: 0.9108 - val_loss: 0.1227 - val_avg_multilabel_BA_2: 0.9108\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1154 - avg_multilabel_BA_2: 0.9107 - val_loss: 0.1266 - val_avg_multilabel_BA_2: 0.9107\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1112 - avg_multilabel_BA_2: 0.9107 - val_loss: 0.1485 - val_avg_multilabel_BA_2: 0.9106\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1154 - avg_multilabel_BA_2: 0.9106 - val_loss: 0.1206 - val_avg_multilabel_BA_2: 0.9106\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1045 - avg_multilabel_BA_2: 0.9106 - val_loss: 0.1171 - val_avg_multilabel_BA_2: 0.9105\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1003 - avg_multilabel_BA_2: 0.9105 - val_loss: 0.1073 - val_avg_multilabel_BA_2: 0.9105\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1038 - avg_multilabel_BA_2: 0.9105 - val_loss: 0.1478 - val_avg_multilabel_BA_2: 0.9104\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1173 - avg_multilabel_BA_2: 0.9104 - val_loss: 0.1159 - val_avg_multilabel_BA_2: 0.9104\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1060 - avg_multilabel_BA_2: 0.9103 - val_loss: 0.1196 - val_avg_multilabel_BA_2: 0.9103\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0995 - avg_multilabel_BA_2: 0.9103 - val_loss: 0.1110 - val_avg_multilabel_BA_2: 0.9103\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0964 - avg_multilabel_BA_2: 0.9103 - val_loss: 0.1596 - val_avg_multilabel_BA_2: 0.9102\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1096 - avg_multilabel_BA_2: 0.9102 - val_loss: 0.1611 - val_avg_multilabel_BA_2: 0.9102\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1121 - avg_multilabel_BA_2: 0.9102 - val_loss: 0.1226 - val_avg_multilabel_BA_2: 0.9101\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1123 - avg_multilabel_BA_2: 0.9101 - val_loss: 0.1415 - val_avg_multilabel_BA_2: 0.9101\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1035 - avg_multilabel_BA_2: 0.9101 - val_loss: 0.1148 - val_avg_multilabel_BA_2: 0.9101\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1031 - avg_multilabel_BA_2: 0.9100 - val_loss: 0.1186 - val_avg_multilabel_BA_2: 0.9100\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0975 - avg_multilabel_BA_2: 0.9100 - val_loss: 0.1166 - val_avg_multilabel_BA_2: 0.9100\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1044 - avg_multilabel_BA_2: 0.9100 - val_loss: 0.1703 - val_avg_multilabel_BA_2: 0.9100\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1096 - avg_multilabel_BA_2: 0.9099 - val_loss: 0.1261 - val_avg_multilabel_BA_2: 0.9099\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0983 - avg_multilabel_BA_2: 0.9099 - val_loss: 0.1388 - val_avg_multilabel_BA_2: 0.9099\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0910 - avg_multilabel_BA_2: 0.9099 - val_loss: 0.1257 - val_avg_multilabel_BA_2: 0.9099\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0929 - avg_multilabel_BA_2: 0.9099 - val_loss: 0.1130 - val_avg_multilabel_BA_2: 0.9099\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0952 - avg_multilabel_BA_2: 0.9098 - val_loss: 0.1306 - val_avg_multilabel_BA_2: 0.9098\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1296 - avg_multilabel_BA_2: 0.9098 - val_loss: 0.1197 - val_avg_multilabel_BA_2: 0.9098\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1124 - avg_multilabel_BA_2: 0.9097 - val_loss: 0.1276 - val_avg_multilabel_BA_2: 0.9097\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1189 - avg_multilabel_BA_2: 0.9097 - val_loss: 0.1225 - val_avg_multilabel_BA_2: 0.9096\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1116 - avg_multilabel_BA_2: 0.9096 - val_loss: 0.1558 - val_avg_multilabel_BA_2: 0.9096\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1083 - avg_multilabel_BA_2: 0.9096 - val_loss: 0.1312 - val_avg_multilabel_BA_2: 0.9095\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1252 - avg_multilabel_BA_2: 0.9095 - val_loss: 0.1284 - val_avg_multilabel_BA_2: 0.9095\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1121 - avg_multilabel_BA_2: 0.9094 - val_loss: 0.1345 - val_avg_multilabel_BA_2: 0.9094\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1139 - avg_multilabel_BA_2: 0.9094 - val_loss: 0.1288 - val_avg_multilabel_BA_2: 0.9094\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1115 - avg_multilabel_BA_2: 0.9093 - val_loss: 0.1279 - val_avg_multilabel_BA_2: 0.9093\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1127 - avg_multilabel_BA_2: 0.9093 - val_loss: 0.1684 - val_avg_multilabel_BA_2: 0.9093\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1147 - avg_multilabel_BA_2: 0.9092 - val_loss: 0.1520 - val_avg_multilabel_BA_2: 0.9092\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1414 - avg_multilabel_BA_2: 0.9092 - val_loss: 0.1509 - val_avg_multilabel_BA_2: 0.9091\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1121 - avg_multilabel_BA_2: 0.9091 - val_loss: 0.1527 - val_avg_multilabel_BA_2: 0.9091\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1096 - avg_multilabel_BA_2: 0.9091 - val_loss: 0.1512 - val_avg_multilabel_BA_2: 0.9090\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1077 - avg_multilabel_BA_2: 0.9090 - val_loss: 0.1378 - val_avg_multilabel_BA_2: 0.9090\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1049 - avg_multilabel_BA_2: 0.9090 - val_loss: 0.1586 - val_avg_multilabel_BA_2: 0.9090\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1116 - avg_multilabel_BA_2: 0.9089 - val_loss: 0.1719 - val_avg_multilabel_BA_2: 0.9089\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1051 - avg_multilabel_BA_2: 0.9089 - val_loss: 0.1373 - val_avg_multilabel_BA_2: 0.9089\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1137 - avg_multilabel_BA_2: 0.9088 - val_loss: 0.1394 - val_avg_multilabel_BA_2: 0.9088\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1065 - avg_multilabel_BA_2: 0.9088 - val_loss: 0.1367 - val_avg_multilabel_BA_2: 0.9088\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1055 - avg_multilabel_BA_2: 0.9088 - val_loss: 0.1290 - val_avg_multilabel_BA_2: 0.9087\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1009 - avg_multilabel_BA_2: 0.9087 - val_loss: 0.1266 - val_avg_multilabel_BA_2: 0.9087\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1084 - avg_multilabel_BA_2: 0.9087 - val_loss: 0.1328 - val_avg_multilabel_BA_2: 0.9087\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0997 - avg_multilabel_BA_2: 0.9086 - val_loss: 0.1277 - val_avg_multilabel_BA_2: 0.9086\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1004 - avg_multilabel_BA_2: 0.9086 - val_loss: 0.1279 - val_avg_multilabel_BA_2: 0.9086\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1122 - avg_multilabel_BA_2: 0.9086 - val_loss: 0.1700 - val_avg_multilabel_BA_2: 0.9085\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1062 - avg_multilabel_BA_2: 0.9085 - val_loss: 0.1438 - val_avg_multilabel_BA_2: 0.9085\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1016 - avg_multilabel_BA_2: 0.9085 - val_loss: 0.1411 - val_avg_multilabel_BA_2: 0.9085\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1115 - avg_multilabel_BA_2: 0.9084 - val_loss: 0.1657 - val_avg_multilabel_BA_2: 0.9084\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1147 - avg_multilabel_BA_2: 0.9084 - val_loss: 0.1295 - val_avg_multilabel_BA_2: 0.9083\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1007 - avg_multilabel_BA_2: 0.9083 - val_loss: 0.1269 - val_avg_multilabel_BA_2: 0.9083\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1041 - avg_multilabel_BA_2: 0.9083 - val_loss: 0.1277 - val_avg_multilabel_BA_2: 0.9083\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1018 - avg_multilabel_BA_2: 0.9083 - val_loss: 0.1476 - val_avg_multilabel_BA_2: 0.9082\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1294 - avg_multilabel_BA_2: 0.9082 - val_loss: 0.1765 - val_avg_multilabel_BA_2: 0.9082\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1137 - avg_multilabel_BA_2: 0.9081 - val_loss: 0.1624 - val_avg_multilabel_BA_2: 0.9081\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1051 - avg_multilabel_BA_2: 0.9081 - val_loss: 0.1321 - val_avg_multilabel_BA_2: 0.9080\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0952 - avg_multilabel_BA_2: 0.9080 - val_loss: 0.1380 - val_avg_multilabel_BA_2: 0.9080\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0997 - avg_multilabel_BA_2: 0.9080 - val_loss: 0.1392 - val_avg_multilabel_BA_2: 0.9080\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0994 - avg_multilabel_BA_2: 0.9080 - val_loss: 0.1336 - val_avg_multilabel_BA_2: 0.9079\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1079 - avg_multilabel_BA_2: 0.9079 - val_loss: 0.1353 - val_avg_multilabel_BA_2: 0.9079\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1002 - avg_multilabel_BA_2: 0.9079 - val_loss: 0.1344 - val_avg_multilabel_BA_2: 0.9079\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0936 - avg_multilabel_BA_2: 0.9079 - val_loss: 0.1323 - val_avg_multilabel_BA_2: 0.9079\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0982 - avg_multilabel_BA_2: 0.9078 - val_loss: 0.1355 - val_avg_multilabel_BA_2: 0.9078\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0995 - avg_multilabel_BA_2: 0.9078 - val_loss: 0.1259 - val_avg_multilabel_BA_2: 0.9078\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1072 - avg_multilabel_BA_2: 0.9078 - val_loss: 0.1550 - val_avg_multilabel_BA_2: 0.9078\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1002 - avg_multilabel_BA_2: 0.9077 - val_loss: 0.1372 - val_avg_multilabel_BA_2: 0.9077\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1019 - avg_multilabel_BA_2: 0.9077 - val_loss: 0.1463 - val_avg_multilabel_BA_2: 0.9077\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1039 - avg_multilabel_BA_2: 0.9077 - val_loss: 0.1399 - val_avg_multilabel_BA_2: 0.9077\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0989 - avg_multilabel_BA_2: 0.9077 - val_loss: 0.1391 - val_avg_multilabel_BA_2: 0.9077\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1379 - avg_multilabel_BA_2: 0.9076 - val_loss: 0.1482 - val_avg_multilabel_BA_2: 0.9075\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1319 - avg_multilabel_BA_2: 0.9074 - val_loss: 0.1500 - val_avg_multilabel_BA_2: 0.9074\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1311 - avg_multilabel_BA_2: 0.9073 - val_loss: 0.1576 - val_avg_multilabel_BA_2: 0.9072\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1292 - avg_multilabel_BA_2: 0.9071 - val_loss: 0.1522 - val_avg_multilabel_BA_2: 0.9070\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1270 - avg_multilabel_BA_2: 0.9069 - val_loss: 0.1509 - val_avg_multilabel_BA_2: 0.9069\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1281 - avg_multilabel_BA_2: 0.9068 - val_loss: 0.1671 - val_avg_multilabel_BA_2: 0.9067\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1336 - avg_multilabel_BA_2: 0.9066 - val_loss: 0.1644 - val_avg_multilabel_BA_2: 0.9065\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1284 - avg_multilabel_BA_2: 0.9064 - val_loss: 0.1510 - val_avg_multilabel_BA_2: 0.9064\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1307 - avg_multilabel_BA_2: 0.9063 - val_loss: 0.1809 - val_avg_multilabel_BA_2: 0.9062\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1290 - avg_multilabel_BA_2: 0.9061 - val_loss: 0.1500 - val_avg_multilabel_BA_2: 0.9060\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1254 - avg_multilabel_BA_2: 0.9059 - val_loss: 0.1613 - val_avg_multilabel_BA_2: 0.9059\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1303 - avg_multilabel_BA_2: 0.9058 - val_loss: 0.1513 - val_avg_multilabel_BA_2: 0.9057\n",
      "Best epoch: 1\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.3579 - avg_multilabel_BA_2: 0.9056 - val_loss: 0.1940 - val_avg_multilabel_BA_2: 0.9054\n",
      "20/20 [==============================] - 0s 568us/step - loss: 1.1746\n",
      "20/20 [==============================] - 0s 495us/step\n",
      "Test results - Loss - Accuracy: 1.174612045288086\n",
      "Averaged Balanced Accuracy: 0.905307\n",
      "[0.9384968, 0.9263551, 0.9128546, 0.90530723]\n"
     ]
    }
   ],
   "source": [
    "paths = ['/home/nonroot/sample_data/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv', \n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv',\n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv',\n",
    "         '/home/nonroot/sample_data/0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv']\n",
    "bas = []\n",
    "\n",
    "for path in paths:\n",
    "\n",
    "    config = {\n",
    "            'df_path': path,\n",
    "            #'df_path': '../full_data/exp_/fold_0/raw_40.csv',\n",
    "            #'neurons_1' : 32, \n",
    "            #'neurons_2' : 16, \n",
    "            'labels': labels\n",
    "    }\n",
    "\n",
    "    har = utils.HAR(config)\n",
    "    #test_results, ba = har.run()\n",
    "    model, best_hps, best_epoch, test_results, ba = har.hypertunning()\n",
    "    bas.append(ba.numpy())\n",
    "    \n",
    "\n",
    "print(bas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f437b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train-test shape: (242349, 226) - X test shape: (60588, 226)\n",
      "y train-test shape: (242349, 6) - y test shape: (60588, 6)\n",
      "Epoch 1/40\n",
      "19388/19388 [==============================] - 16s 794us/step - loss: 51.7867 - val_loss: 32.7636\n",
      "Epoch 2/40\n",
      "19388/19388 [==============================] - 15s 791us/step - loss: 138.8578 - val_loss: 145.2188\n",
      "Epoch 3/40\n",
      "19388/19388 [==============================] - 15s 793us/step - loss: 222.4855 - val_loss: 149.7679\n",
      "Epoch 4/40\n",
      "19388/19388 [==============================] - 15s 795us/step - loss: 305.4887 - val_loss: 309.1640\n",
      "Epoch 5/40\n",
      "19388/19388 [==============================] - 15s 789us/step - loss: 387.3051 - val_loss: 681.7822\n",
      "Epoch 6/40\n",
      "19388/19388 [==============================] - 15s 796us/step - loss: 468.6788 - val_loss: 288.7400\n",
      "Epoch 7/40\n",
      "19388/19388 [==============================] - 16s 800us/step - loss: 548.9426 - val_loss: 566.7703\n",
      "Epoch 8/40\n",
      "19388/19388 [==============================] - 15s 799us/step - loss: 629.5294 - val_loss: 581.9187\n",
      "Epoch 9/40\n",
      "19388/19388 [==============================] - 15s 789us/step - loss: 714.6686 - val_loss: 371.5422\n",
      "Epoch 10/40\n",
      "19388/19388 [==============================] - 15s 788us/step - loss: 787.3315 - val_loss: 698.0351\n",
      "Epoch 11/40\n",
      "19388/19388 [==============================] - 15s 796us/step - loss: 883.8996 - val_loss: 1266.7197\n",
      "Epoch 12/40\n",
      "19388/19388 [==============================] - 15s 791us/step - loss: 978.6187 - val_loss: 1480.9521\n",
      "Epoch 13/40\n",
      "19388/19388 [==============================] - 15s 785us/step - loss: 1024.6997 - val_loss: 2434.6875\n",
      "Epoch 14/40\n",
      "19388/19388 [==============================] - 15s 798us/step - loss: 1115.9875 - val_loss: 1652.9343\n",
      "Epoch 15/40\n",
      "19388/19388 [==============================] - 15s 793us/step - loss: 1191.6636 - val_loss: 1274.7557\n",
      "Epoch 16/40\n",
      "19388/19388 [==============================] - 15s 793us/step - loss: 1267.5042 - val_loss: 1104.2228\n",
      "Epoch 17/40\n",
      "19388/19388 [==============================] - 15s 797us/step - loss: 1367.8474 - val_loss: 1738.0582\n",
      "Epoch 18/40\n",
      "19388/19388 [==============================] - 15s 790us/step - loss: 1457.8140 - val_loss: 3700.8855\n",
      "Epoch 19/40\n",
      "19388/19388 [==============================] - 15s 793us/step - loss: 1547.0576 - val_loss: 2325.5408\n",
      "Epoch 20/40\n",
      "19388/19388 [==============================] - 15s 796us/step - loss: 1617.0704 - val_loss: 963.8701\n",
      "Epoch 21/40\n",
      "19388/19388 [==============================] - 15s 793us/step - loss: 1662.3209 - val_loss: 1239.6860\n",
      "Epoch 22/40\n",
      "19388/19388 [==============================] - 16s 800us/step - loss: 1756.2554 - val_loss: 2152.4414\n",
      "Epoch 23/40\n",
      "19388/19388 [==============================] - 15s 798us/step - loss: 1853.9187 - val_loss: 2805.0703\n",
      "Epoch 24/40\n",
      "19388/19388 [==============================] - 15s 792us/step - loss: 1921.8035 - val_loss: 2133.1145\n",
      "Epoch 25/40\n",
      "19388/19388 [==============================] - 15s 796us/step - loss: 2000.8403 - val_loss: 3064.6433\n",
      "Epoch 26/40\n",
      "19388/19388 [==============================] - 15s 789us/step - loss: 2082.1785 - val_loss: 2760.4539\n",
      "Epoch 27/40\n",
      "19388/19388 [==============================] - 15s 792us/step - loss: 2144.9167 - val_loss: 1244.5280\n",
      "Epoch 28/40\n",
      "19388/19388 [==============================] - 15s 796us/step - loss: 2252.0076 - val_loss: 970.8933\n",
      "Epoch 29/40\n",
      "19346/19388 [============================>.] - ETA: 0s - loss: 2331.9409"
     ]
    }
   ],
   "source": [
    "\n",
    "bas = []\n",
    "config = {\n",
    "        #'df_path': path,\n",
    "        'df_path': './sample_data/exp_/fold_0/raw_40.csv',\n",
    "        'neurons_1' : 32, \n",
    "        'neurons_2' : 16, \n",
    "        'labels': labels\n",
    "}\n",
    "\n",
    "har = utils.HAR(config)\n",
    "test_results, ba = har.run()\n",
    "#model, best_hps, best_epoch, test_results, ba = har.hypertunning()\n",
    "bas.append(ba.numpy())\n",
    "\n",
    "\n",
    "print(bas)\n",
    "print(max(bas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3381983",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'har' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nonroot/har_2.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f73686172705f74686f6d70736f6e227d/home/nonroot/har_2.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m har\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'har' is not defined"
     ]
    }
   ],
   "source": [
    "har.data.x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2663f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "bas = []\n",
    "folderpath = '/home/wander/OtherProjects/har_flower/sample_data'\n",
    "for path in glob.iglob(f'{folderpath}/**.csv', recursive=True):\n",
    "    config = {\n",
    "            'df_path': path,\n",
    "            #'df_path': './sample_data/exp_/fold_0/raw_40.csv',\n",
    "            #'neurons_1' : 32, \n",
    "            #'neurons_2' : 16,\n",
    "            #'from_saved': ../full_data/exp_/saved_model_fold_0,\n",
    "            'labels': labels\n",
    "    }\n",
    "\n",
    "    har = utils.HAR(config)\n",
    "    #test_results, ba = har.run()\n",
    "    model, best_hps, best_epoch, test_results, ba = har.hypertunning()\n",
    "    bas.append(ba.numpy())\n",
    "    \n",
    "\n",
    "print(bas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 56)                12712     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 456       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,222\n",
      "Trainable params: 13,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "har.mlp.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf03635",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPMultilabel' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nonroot/har_2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f73686172705f74686f6d70736f6e227d/home/nonroot/har_2.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m har\u001b[39m.\u001b[39;49mmlp\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39mx_train\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPMultilabel' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "har.mlp.data.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 44)                9988      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 270       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,258\n",
      "Trainable params: 10,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "bas = []\n",
    "path = '/home/nonroot/sample_data/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv'\n",
    "config = {\n",
    "        'df_path': path,\n",
    "        #'df_path': './sample_data/exp_/fold_0/raw_40.csv',\n",
    "        #'neurons_1' : 32, \n",
    "        #'neurons_2' : 16,\n",
    "        'from_saved': '../full_data/exp_/saved_model_fold_0',\n",
    "        'labels': labels\n",
    "}\n",
    "\n",
    "har = utils.HAR(config)\n",
    "#test_results, ba = har.run()\n",
    "#model, best_hps, best_epoch, test_results, ba = har.hypertunning()\n",
    "#bas.append(ba.numpy())\n",
    "\n",
    "\n",
    "#print(bas)\n",
    "har.mlp.model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14ac76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
