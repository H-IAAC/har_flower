{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776a75ae",
   "metadata": {},
   "source": [
    "# Aprendizado Federado para reconhecimento de contexto em dispositivos móveis\n",
    "## Experimento 1 - Pré-treinamento usual com uma base de usuários e Aprendizado Federado embarcado partindo do modelo pretreinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48669192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import es_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcbddc",
   "metadata": {},
   "source": [
    "Inicialmente precisamos separar quais 'labels' usaremos. Aqui, optamos pelas 51 labels que segundo artigo do ExtraSensosy utiliza, de modo a ter bons parâmetros de comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9654a2bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"labels = ['label:LYING_DOWN',\\n 'label:SITTING',\\n 'label:FIX_walking',\\n 'label:FIX_running',\\n 'label:BICYCLING',\\n 'label:SLEEPING',\\n 'label:LAB_WORK',\\n 'label:IN_CLASS',\\n 'label:IN_A_MEETING',\\n 'label:LOC_main_workplace',\\n 'label:OR_indoors',\\n 'label:OR_outside',\\n 'label:IN_A_CAR',\\n 'label:ON_A_BUS',\\n 'label:DRIVE_-_I_M_THE_DRIVER',\\n 'label:DRIVE_-_I_M_A_PASSENGER',\\n 'label:LOC_home',\\n 'label:FIX_restaurant',\\n 'label:PHONE_IN_POCKET',\\n 'label:OR_exercise',\\n 'label:COOKING',\\n 'label:SHOPPING',\\n 'label:STROLLING',\\n 'label:DRINKING__ALCOHOL_',\\n 'label:BATHING_-_SHOWER',\\n 'label:CLEANING',\\n 'label:DOING_LAUNDRY',\\n 'label:WASHING_DISHES',\\n 'label:WATCHING_TV',\\n 'label:SURFING_THE_INTERNET',\\n 'label:AT_A_PARTY',\\n 'label:AT_A_BAR',\\n 'label:LOC_beach',\\n 'label:SINGING',\\n 'label:TALKING',\\n 'label:COMPUTER_WORK',\\n 'label:EATING',\\n 'label:TOILET',\\n 'label:GROOMING',\\n 'label:DRESSING',\\n 'label:AT_THE_GYM',\\n 'label:STAIRS_-_GOING_UP',\\n 'label:STAIRS_-_GOING_DOWN',\\n 'label:ELEVATOR',\\n 'label:OR_standing',\\n 'label:AT_SCHOOL',\\n 'label:PHONE_IN_HAND',\\n 'label:PHONE_IN_BAG',\\n 'label:PHONE_ON_TABLE',\\n 'label:WITH_CO-WORKERS',\\n 'label:WITH_FRIENDS']\\n\\nlen(labels)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''labels = ['label:LYING_DOWN',\n",
    " 'label:SITTING',\n",
    " 'label:FIX_walking',\n",
    " 'label:FIX_running',\n",
    " 'label:BICYCLING',\n",
    " 'label:SLEEPING',\n",
    " 'label:LAB_WORK',\n",
    " 'label:IN_CLASS',\n",
    " 'label:IN_A_MEETING',\n",
    " 'label:LOC_main_workplace',\n",
    " 'label:OR_indoors',\n",
    " 'label:OR_outside',\n",
    " 'label:IN_A_CAR',\n",
    " 'label:ON_A_BUS',\n",
    " 'label:DRIVE_-_I_M_THE_DRIVER',\n",
    " 'label:DRIVE_-_I_M_A_PASSENGER',\n",
    " 'label:LOC_home',\n",
    " 'label:FIX_restaurant',\n",
    " 'label:PHONE_IN_POCKET',\n",
    " 'label:OR_exercise',\n",
    " 'label:COOKING',\n",
    " 'label:SHOPPING',\n",
    " 'label:STROLLING',\n",
    " 'label:DRINKING__ALCOHOL_',\n",
    " 'label:BATHING_-_SHOWER',\n",
    " 'label:CLEANING',\n",
    " 'label:DOING_LAUNDRY',\n",
    " 'label:WASHING_DISHES',\n",
    " 'label:WATCHING_TV',\n",
    " 'label:SURFING_THE_INTERNET',\n",
    " 'label:AT_A_PARTY',\n",
    " 'label:AT_A_BAR',\n",
    " 'label:LOC_beach',\n",
    " 'label:SINGING',\n",
    " 'label:TALKING',\n",
    " 'label:COMPUTER_WORK',\n",
    " 'label:EATING',\n",
    " 'label:TOILET',\n",
    " 'label:GROOMING',\n",
    " 'label:DRESSING',\n",
    " 'label:AT_THE_GYM',\n",
    " 'label:STAIRS_-_GOING_UP',\n",
    " 'label:STAIRS_-_GOING_DOWN',\n",
    " 'label:ELEVATOR',\n",
    " 'label:OR_standing',\n",
    " 'label:AT_SCHOOL',\n",
    " 'label:PHONE_IN_HAND',\n",
    " 'label:PHONE_IN_BAG',\n",
    " 'label:PHONE_ON_TABLE',\n",
    " 'label:WITH_CO-WORKERS',\n",
    " 'label:WITH_FRIENDS']\n",
    "\n",
    "len(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba32040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\n",
    "    'label:OR_standing',\n",
    "    'label:SITTING',\n",
    "    'label:LYING_DOWN',\n",
    "    'label:FIX_running',\n",
    "    'label:FIX_walking',\n",
    "    'label:BICYCLING'\n",
    "]\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4102452",
   "metadata": {},
   "source": [
    "Separamos os 60 usuários em 5 pastas onde cada pasta considera 40 usuários selecionados aleatoriamente para treino e os 20 restantes para teste. Os dados dos 20 usuários são ainda separados em 4 arquivos *.csv* (x_train, x_test, y_train, y_test) e colocados em pastas nomeadas com o uuid do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea84e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_folds = utils.create_k_folds_n_users(5, 3, '/home/wander/OtherProjects/har_flower/sample_data')\n",
    "k_folds = utils.create_k_folds_n_users(5, 40, '/home/wander/OtherProjects/har_flower/full_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e1e8e",
   "metadata": {},
   "source": [
    "Em seguida, para cada pasta, treinamos um modelo de MLP fazendo uma otimização de hiperparâmetros e convertemos em um modelo *tflite*. Os hiperparâmetros otimizados são:\n",
    "\n",
    "- número de camadas escondidas (*hidden layers*): 1 ou 2\n",
    "- número de neurônios em cada camada escondida: 4 a 64, com um passo de tamanho 4\n",
    "- constante de penalização da regularização L2 em cada camada: 1e-2, 1e-3 ou 1e-4\n",
    "- taxa de aprendizado (*learning rate*) do otimizador (*Stochastic Gradient Descent*, **SGD**): 1e-1, 1e-2, 1e-3 ou 1e-4\n",
    "- momentum do otimizador (**SGD**): 0.8, 0.5, 0.3 ou 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc2386d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 20s]\n",
      "val_categorical_accuracy: 0.38854455947875977\n",
      "\n",
      "Best val_categorical_accuracy So Far: 0.38854455947875977\n",
      "Total elapsed time: 00h 07m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "3266/3266 [==============================] - 3s 823us/step - loss: 117761056768.0000 - categorical_accuracy: 0.3719 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 2/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 3/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 4/100\n",
      "3266/3266 [==============================] - 3s 774us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 5/100\n",
      "3266/3266 [==============================] - 3s 771us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 6/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 7/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 8/100\n",
      "3266/3266 [==============================] - 3s 770us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 9/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 10/100\n",
      "3266/3266 [==============================] - 2s 761us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 11/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 12/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 13/100\n",
      "3266/3266 [==============================] - 2s 761us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 14/100\n",
      "3266/3266 [==============================] - 3s 772us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 15/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7863 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 16/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 17/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 18/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 19/100\n",
      "3266/3266 [==============================] - 3s 776us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 20/100\n",
      "3266/3266 [==============================] - 3s 775us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 21/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 22/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 23/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 24/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 25/100\n",
      "3266/3266 [==============================] - 3s 777us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 26/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 27/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 28/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 29/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 30/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 31/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 32/100\n",
      "3266/3266 [==============================] - 3s 768us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 33/100\n",
      "3266/3266 [==============================] - 3s 771us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 34/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 35/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 36/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 37/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 38/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 39/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 40/100\n",
      "3266/3266 [==============================] - 2s 763us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 41/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 42/100\n",
      "3266/3266 [==============================] - 3s 771us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 43/100\n",
      "3266/3266 [==============================] - 3s 775us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 44/100\n",
      "3266/3266 [==============================] - 2s 759us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 45/100\n",
      "3266/3266 [==============================] - 3s 768us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 46/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 47/100\n",
      "3266/3266 [==============================] - 2s 759us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 49/100\n",
      "3266/3266 [==============================] - 2s 763us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 50/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 51/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 52/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 53/100\n",
      "3266/3266 [==============================] - 3s 773us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 54/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 55/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 56/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 57/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 58/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 59/100\n",
      "3266/3266 [==============================] - 3s 770us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 60/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 61/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 62/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 63/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 64/100\n",
      "3266/3266 [==============================] - 3s 770us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 65/100\n",
      "3266/3266 [==============================] - 2s 758us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 66/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 67/100\n",
      "3266/3266 [==============================] - 2s 761us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 68/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 69/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 70/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 71/100\n",
      "3266/3266 [==============================] - 2s 761us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 72/100\n",
      "3266/3266 [==============================] - 3s 774us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 73/100\n",
      "3266/3266 [==============================] - 3s 768us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 74/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 75/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 76/100\n",
      "3266/3266 [==============================] - 2s 761us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 77/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 78/100\n",
      "3266/3266 [==============================] - 2s 763us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 79/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 80/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 81/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 82/100\n",
      "3266/3266 [==============================] - 3s 770us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 83/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 84/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 85/100\n",
      "3266/3266 [==============================] - 3s 766us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 86/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 87/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 88/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 89/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 90/100\n",
      "3266/3266 [==============================] - 3s 772us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 91/100\n",
      "3266/3266 [==============================] - 3s 768us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 92/100\n",
      "3266/3266 [==============================] - 3s 767us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 93/100\n",
      "3266/3266 [==============================] - 3s 768us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 94/100\n",
      "3266/3266 [==============================] - 3s 769us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 95/100\n",
      "3266/3266 [==============================] - 2s 762us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3266/3266 [==============================] - 2s 763us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 97/100\n",
      "3266/3266 [==============================] - 2s 760us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 98/100\n",
      "3266/3266 [==============================] - 3s 773us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 99/100\n",
      "3266/3266 [==============================] - 2s 764us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Epoch 100/100\n",
      "3266/3266 [==============================] - 2s 765us/step - loss: 0.7862 - categorical_accuracy: 0.3720 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "Best epoch: 1\n",
      "3266/3266 [==============================] - 3s 823us/step - loss: 101001166848.0000 - categorical_accuracy: 0.3719 - val_loss: nan - val_categorical_accuracy: 0.3885\n",
      "1472/1472 [==============================] - 1s 507us/step - loss: nan - categorical_accuracy: 0.3696\n",
      "Test results - Loss: nan - Accuracy: 0.36955922842025757%\n",
      "Averaged Balanced Accuracy: 0.583333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 13:33:34.298464: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/saved_model_fold_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 13:33:34.755651: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2022-03-22 13:33:34.755669: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2022-03-22 13:33:34.755673: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:372] Ignored change_concat_input_ranges.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "2022-03-22 13:33:34.756277: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: model/saved_model_fold_0\n",
      "2022-03-22 13:33:34.757777: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-03-22 13:33:34.757789: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: model/saved_model_fold_0\n",
      "2022-03-22 13:33:34.761404: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-03-22 13:33:34.799181: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: model/saved_model_fold_0\n",
      "2022-03-22 13:33:34.810309: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 54033 microseconds.\n",
      "2022-03-22 13:33:34.832352: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold in k_folds:\n",
    "    config = {\n",
    "        'df_path': k_folds[fold]['40'],\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    har = utils.HAR(config)\n",
    "    #har.run()\n",
    "    har.hypertunning()\n",
    "    \n",
    "    har.mlp.model.save(f'model/saved_model_{fold}')\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'model/saved_model_{fold}') # path to the SavedModel directory\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f'model/model_base_{fold}.tflite', 'wb') as f:\n",
    "      f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb1d79",
   "metadata": {},
   "source": [
    "Com os modelos salvos, o restante do experimento segue em ambiente Android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "har.mlp.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "\n",
    "\n",
    "raw = k_folds['fold_0']['train']\n",
    "x =raw[raw.columns.drop(raw.filter(regex='label:'))]\n",
    "y = raw.filter(regex='label:')\n",
    "#x_train, x_test, y_train, y_test  = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, y_train, x_test, y_test = iterative_train_test_split(x, y, test_size = 0.1)\n",
    "#raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = har.mlp.model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_multilabel_BA(y_truei, y_predi):\n",
    "    ba_array = []\n",
    "    y_true, y_pred = remove_nans_np(y_truei, y_predi)\n",
    "    #print(y_pred.shape)\n",
    "    print(len(y_true))\n",
    "    print(len(y_truei))\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        report = classification_report(y_true.to_numpy()[:, i], (y_pred[:, i] > 0.5), output_dict=True, zero_division=0)\n",
    "        #sensitivity = report['1.0']['recall'] # tp / (tp + fn)\n",
    "        specificity = report['0.0']['recall'] #specificity = tn / (tn+fp)\n",
    "        try:\n",
    "            sensitivity = report['1.0']['recall'] # tp / (tp + fn)\n",
    "        except:\n",
    "            sensitivity = specificity # tp / (tp + fn)\n",
    "        ba = 0.5*(specificity+sensitivity)\n",
    "        ba_array.append(ba)\n",
    "    return np.mean(ba_array)\n",
    "\n",
    "\n",
    "def remove_nans_np(x, y):\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    #mask = math.logical_and(math.logical_not(math.is_nan(x)), math.logical_not(math.is_nan(y)))\n",
    "    \n",
    "    marra = np.ma.MaskedArray(x, mask=~mask)\n",
    "    marrb = np.ma.MaskedArray(y, mask=~mask)\n",
    "\n",
    "    return np.ma.compressed(marra), np.ma.compressed(marrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732aa87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_multilabel_BA(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[raw.columns.drop(raw.filter(regex='label:'))].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e18772",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(regex='label:')['label:SITTING'].loc [raw.filter(regex='label:')['label:SITTING'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8524478",
   "metadata": {},
   "source": [
    "raw = pd.read_csv('../input/user1.features_labels.csv')\n",
    "har = utils.HAR(config)\n",
    "har.run()\n",
    "#har.hypertunning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
